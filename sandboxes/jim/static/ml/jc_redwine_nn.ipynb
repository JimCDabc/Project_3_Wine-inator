{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "# !pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "# !pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import utils\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras import datasets\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import History\n",
    "\n",
    "from keras import losses\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "# from keras.optimizers import SGD\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed=231\n",
    "np.random.seed(231)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### White wine source data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# white_datafile = os.path.join(\"..\", \"data\", \"sourcedata\", \"winequality-white.csv\")\n",
    "# print(white_datafile)\n",
    "\n",
    "# white_df = pd.read_csv(white_datafile, delimiter=\";\")\n",
    "# white_df.sort_values(by=['pH'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Red wine source data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\sourcedata\\winequality-red.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>10.7</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.070</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.99720</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.65</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.99600</td>\n",
       "      <td>3.23</td>\n",
       "      <td>1.10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>5.6</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.045</td>\n",
       "      <td>12.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.99240</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.82</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>9.1</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.071</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.99462</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.69</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>8.6</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.068</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.99516</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.69</td>\n",
       "      <td>11.7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>7.4</td>\n",
       "      <td>1.185</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.097</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.63</td>\n",
       "      <td>0.54</td>\n",
       "      <td>10.7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.082</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99808</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.52</td>\n",
       "      <td>10.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>8.3</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.084</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.99892</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>7.6</td>\n",
       "      <td>1.580</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.137</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.99476</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>10.9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>10.4</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.145</td>\n",
       "      <td>34.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.99832</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.86</td>\n",
       "      <td>9.9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "495            10.7             0.350         0.53            2.60      0.070   \n",
       "1403            7.2             0.330         0.33            1.70      0.061   \n",
       "390             5.6             0.850         0.05            1.40      0.045   \n",
       "1061            9.1             0.400         0.50            1.80      0.071   \n",
       "1202            8.6             0.420         0.39            1.80      0.068   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "690             7.4             1.185         0.00            4.25      0.097   \n",
       "1478            7.1             0.875         0.05            5.70      0.082   \n",
       "899             8.3             1.020         0.02            3.40      0.084   \n",
       "1299            7.6             1.580         0.00            2.10      0.137   \n",
       "832            10.4             0.440         0.42            1.50      0.145   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "495                   5.0                  16.0  0.99720  3.15       0.65   \n",
       "1403                  3.0                  13.0  0.99600  3.23       1.10   \n",
       "390                  12.0                  88.0  0.99240  3.56       0.82   \n",
       "1061                  7.0                  16.0  0.99462  3.21       0.69   \n",
       "1202                  6.0                  12.0  0.99516  3.35       0.69   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "690                   5.0                  14.0  0.99660  3.63       0.54   \n",
       "1478                  3.0                  14.0  0.99808  3.40       0.52   \n",
       "899                   6.0                  11.0  0.99892  3.48       0.49   \n",
       "1299                  5.0                   9.0  0.99476  3.50       0.40   \n",
       "832                  34.0                  48.0  0.99832  3.38       0.86   \n",
       "\n",
       "      alcohol  quality  \n",
       "495      11.0        8  \n",
       "1403     10.0        8  \n",
       "390      12.9        8  \n",
       "1061     12.5        8  \n",
       "1202     11.7        8  \n",
       "...       ...      ...  \n",
       "690      10.7        3  \n",
       "1478     10.2        3  \n",
       "899      11.0        3  \n",
       "1299     10.9        3  \n",
       "832       9.9        3  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafile = os.path.join(\"..\", \"data\", \"sourcedata\", \"winequality-red.csv\")\n",
    "print(datafile)\n",
    "\n",
    "red_df = pd.read_csv(datafile, delimiter=\";\")\n",
    "red_df.head()\n",
    "red_df.sort_values(by=['quality'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Features and Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = red_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set the target attribute (y axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [5],\n",
       "       [5],\n",
       "       ...,\n",
       "       [6],\n",
       "       [5],\n",
       "       [6]], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = wine_df[\"quality\"].values.reshape(-1,1)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### drop the target (quality) column from data to have dataeframe of just the attributes we are regressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  \n",
       "0         9.4  \n",
       "1         9.8  \n",
       "2         9.8  \n",
       "3         9.8  \n",
       "4         9.4  \n",
       "...       ...  \n",
       "1594     10.5  \n",
       "1595     11.2  \n",
       "1596     11.0  \n",
       "1597     10.2  \n",
       "1598     11.0  \n",
       "\n",
       "[1599 rows x 11 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = wine_df.drop(\"quality\", axis=1)\n",
    "feature_names = X.columns\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### split the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# X_scaler = StandardScaler().fit(X_train)\n",
    "# y_scaler = StandardScaler().fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimco\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "X_scaler = PowerTransformer(method='yeo-johnson').fit(X_train)\n",
    "y_scaler = PowerTransformer(method='yeo-johnson').fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import QuantileTransformer\n",
    "# X_scaler = QuantileTransformer(output_distribution='normal').fit(X_train)\n",
    "# y_scaler = QuantileTransformer(output_distribution='normal').fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# X_scaler = MinMaxScaler(feature_range=(0, 1)).fit(X_train)\n",
    "# y_scaler = MinMaxScaler(feature_range=(0, 1)).fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MaxAbsScaler\n",
    "# X_scaler = MaxAbsScaler().fit(X_train)\n",
    "# y_scaler = MaxAbsScaler().fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import RobustScaler\n",
    "# X_scaler = RobustScaler(quantile_range=(25, 75)).fit(X_train)\n",
    "# y_scaler = RobustScaler(quantile_range=(25, 75)).fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Label-encode data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 2 - One hot encode the label encoded data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding label encoded data\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "y_train_categorical[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_y_train[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_categorical[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_y_test[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from keras.constraints import maxnorm\n",
    "# from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create a normal neural network with 2 inputs, 6 hidden nodes, and 2 outputs\n",
    "### first Model: \n",
    "# model = Sequential()\n",
    "\n",
    "# number_inputs = 39\n",
    "# number_hidden_nodes = 100\n",
    "# number_classes = 3\n",
    "\n",
    "# model.add(Dense(units=number_hidden_nodes,\n",
    "#                 activation='relu', input_dim=number_inputs))\n",
    "# model.add(Dense(units=number_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model Function to create, compile and return a Keras NN model\n",
    "#model.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "\n",
    "def create_model (activation='relu', dropout_rate=0.2, hidden_units=100, \n",
    "                  optimizer='adam', loss='mse', metrics='accuracy'):\n",
    "      \n",
    "    #create model (11 inputs, 2 hidden layers, a droupout layer between each hidden layer, 1 outputs)\n",
    "    number_inputs = 11\n",
    "    number_outputs = 9\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    ## layer-1: Input \n",
    "    ## Layer-2: 1st hidden layer\n",
    "    model.add(Dense(input_dim=number_inputs, units=hidden_units, \n",
    "                    activation=activation\n",
    "                   ))\n",
    "    \n",
    "    # Layer-3 dropout  layer between hidden layers \n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Layer-4: 2nd hidden layer\n",
    "    model.add(Dense(units=100, \n",
    "                    activation=activation\n",
    "                   ))\n",
    "   \n",
    "   \n",
    "    # layer-8 output layer\n",
    "    model.add(Dense(units=number_outputs,\n",
    "                    #kernel_initializer=init_mode,\n",
    "                    activation='softmax'))\n",
    "    \n",
    "    ## Compile the Model\n",
    "    ## Now that we have our model architecture defined, \n",
    "    ## we must compile the model using a loss function and optimizer. \n",
    "    ## We can also specify additional training metrics such as accuracy.\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=[metrics])\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model Function to create, compile and return a Keras NN model\n",
    "# def create_complex_model (activation='relu', dropout_rate=0.2, hidden_units=100, \n",
    "#                   optimizer='adam', loss='categorical_crossentropy', metrics='accuracy'):\n",
    "      \n",
    "#     #create model (39 inputs, 3 hidden layers, a droupout layer between each hidden layer, 3 outputs)\n",
    "#     number_inputs = 39\n",
    "#     #number_hidden_nodes = 100 # (3 hidden layers)\n",
    "#     number_classes = 3\n",
    "    \n",
    "#     model = Sequential()\n",
    "    \n",
    "#     ## layer-1: Input \n",
    "#     ## Layer-2: 1st hidden layer\n",
    "#     model.add(Dense(input_dim=number_inputs, units=hidden_units, \n",
    "#                     activation=activation\n",
    "#                     #kernel_initializer=init_mode,\n",
    "#                     #kernel_constraint=maxnorm(weight_constraint)\n",
    "#                    ))\n",
    "    \n",
    "#     # Layer-3 dropout  layer between hidden layers \n",
    "#     model.add(Dropout(dropout_rate))\n",
    "    \n",
    "#     # Layer-4: 2nd hidden layer\n",
    "#     model.add(Dense(units=hidden_units, \n",
    "#                     activation=activation\n",
    "#                     #kernel_initializer=init_mode,\n",
    "#                     #kernel_constraint=maxnorm(weight_constraint)\n",
    "#                    ))\n",
    "    \n",
    "#     # layer-5: dropout between hidden layers \n",
    "#     model.add(Dropout(dropout_rate))\n",
    "    \n",
    "#     # layer-6 hidden layer\n",
    "#     model.add(Dense(units=hidden_units, \n",
    "#                     activation=activation\n",
    "#                     #kernel_initializer=init_mode,\n",
    "#                     #kernel_constraint=maxnorm(weight_constraint)\n",
    "#                    ))\n",
    "    \n",
    "#     # layer-7: dropout between hidden layer and output layer \n",
    "# #     model.add(Dropout(dropout_rate))\n",
    "    \n",
    "#     # layer-8 output layer\n",
    "#     model.add(Dense(units=number_classes,\n",
    "#                     #kernel_initializer=init_mode,\n",
    "#                     activation='softmax'))\n",
    "    \n",
    "#     ## Compile the Model\n",
    "#     ## Now that we have our model architecture defined, \n",
    "#     ## we must compile the model using a loss function and optimizer. \n",
    "#     ## We can also specify additional training metrics such as accuracy.\n",
    "#     model.compile(optimizer=optimizer,\n",
    "#                   loss=loss,\n",
    "#                   metrics=[metrics])\n",
    "    \n",
    "#     return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2nd model\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 100)               1200      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 9)                 909       \n",
      "=================================================================\n",
      "Total params: 12,209\n",
      "Trainable params: 12,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=100\n",
    "# epochs=100\n",
    "# # # model = KerasClassifier(build_fn=create_model, batch_size=batch_size, epochs=epochs)\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use SGD optimizer\n",
    "# from keras.optimizers import SGD\n",
    "\n",
    "# sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "\n",
    "# # Use categorical crossentropy for categorical data and mean squared error for regression\n",
    "# # Hint: your output layer in this example is using software for logistic regression (categorical)\n",
    "# # If your output layer activation was `linear` then you may want to use `mse` for loss\n",
    "# model.compile(optimizer=sgd,\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Using RMS optimizer \n",
    "\n",
    "# from keras.optimizers import RMSprop\n",
    "\n",
    "# # defining the parameters for RMSprop (I used the keras defaults here)\n",
    "# rms = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "# # Use categorical crossentropy for categorical data and mean squared error for regression\n",
    "# # Hint: your output layer in this example is using software for logistic regression (categorical)\n",
    "# # If your output layer activation was `linear` then you may want to use `mse` for loss\n",
    "# model.compile(optimizer=rms,\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use categorical crossentropy for categorical data and mean squared error for regression\n",
    "# Hint: your output layer in this example is using software for logistic regression (categorical)\n",
    "# If your output layer activation was `linear` then you may want to use `mse` for loss\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1199 samples, validate on 400 samples\n",
      "Epoch 1/300\n",
      "1199/1199 [==============================] - 1s 855us/step - loss: 0.0922 - accuracy: 0.3028 - val_loss: 0.0816 - val_accuracy: 0.5100\n",
      "Epoch 2/300\n",
      "1199/1199 [==============================] - 0s 48us/step - loss: 0.0749 - accuracy: 0.5188 - val_loss: 0.0702 - val_accuracy: 0.5375\n",
      "Epoch 3/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0656 - accuracy: 0.5446 - val_loss: 0.0643 - val_accuracy: 0.5475\n",
      "Epoch 4/300\n",
      "1199/1199 [==============================] - 0s 49us/step - loss: 0.0617 - accuracy: 0.5838 - val_loss: 0.0614 - val_accuracy: 0.6125\n",
      "Epoch 5/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0603 - accuracy: 0.5922 - val_loss: 0.0609 - val_accuracy: 0.6000\n",
      "Epoch 6/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0600 - accuracy: 0.5922 - val_loss: 0.0605 - val_accuracy: 0.6100\n",
      "Epoch 7/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0595 - accuracy: 0.6063 - val_loss: 0.0600 - val_accuracy: 0.6075\n",
      "Epoch 8/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0579 - accuracy: 0.6180 - val_loss: 0.0597 - val_accuracy: 0.6025\n",
      "Epoch 9/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0586 - accuracy: 0.6013 - val_loss: 0.0601 - val_accuracy: 0.6000\n",
      "Epoch 10/300\n",
      "1199/1199 [==============================] - 0s 49us/step - loss: 0.0570 - accuracy: 0.6314 - val_loss: 0.0596 - val_accuracy: 0.6100\n",
      "Epoch 11/300\n",
      "1199/1199 [==============================] - 0s 49us/step - loss: 0.0568 - accuracy: 0.6230 - val_loss: 0.0598 - val_accuracy: 0.6125\n",
      "Epoch 12/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0567 - accuracy: 0.6280 - val_loss: 0.0595 - val_accuracy: 0.6000\n",
      "Epoch 13/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0559 - accuracy: 0.6455 - val_loss: 0.0599 - val_accuracy: 0.6100\n",
      "Epoch 14/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0561 - accuracy: 0.6389 - val_loss: 0.0592 - val_accuracy: 0.6175\n",
      "Epoch 15/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0559 - accuracy: 0.6347 - val_loss: 0.0594 - val_accuracy: 0.6075\n",
      "Epoch 16/300\n",
      "1199/1199 [==============================] - 0s 49us/step - loss: 0.0553 - accuracy: 0.6514 - val_loss: 0.0592 - val_accuracy: 0.6150\n",
      "Epoch 17/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0551 - accuracy: 0.6489 - val_loss: 0.0591 - val_accuracy: 0.6175\n",
      "Epoch 18/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0552 - accuracy: 0.6355 - val_loss: 0.0588 - val_accuracy: 0.6200\n",
      "Epoch 19/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0545 - accuracy: 0.6555 - val_loss: 0.0591 - val_accuracy: 0.6150\n",
      "Epoch 20/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0543 - accuracy: 0.6589 - val_loss: 0.0586 - val_accuracy: 0.6225\n",
      "Epoch 21/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0540 - accuracy: 0.6489 - val_loss: 0.0587 - val_accuracy: 0.6125\n",
      "Epoch 22/300\n",
      "1199/1199 [==============================] - 0s 49us/step - loss: 0.0534 - accuracy: 0.6689 - val_loss: 0.0590 - val_accuracy: 0.6225\n",
      "Epoch 23/300\n",
      "1199/1199 [==============================] - 0s 87us/step - loss: 0.0535 - accuracy: 0.6597 - val_loss: 0.0587 - val_accuracy: 0.6250\n",
      "Epoch 24/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0535 - accuracy: 0.6547 - val_loss: 0.0588 - val_accuracy: 0.6200\n",
      "Epoch 25/300\n",
      "1199/1199 [==============================] - 0s 46us/step - loss: 0.0535 - accuracy: 0.6606 - val_loss: 0.0587 - val_accuracy: 0.6275\n",
      "Epoch 26/300\n",
      "1199/1199 [==============================] - 0s 47us/step - loss: 0.0525 - accuracy: 0.6672 - val_loss: 0.0591 - val_accuracy: 0.6275\n",
      "Epoch 27/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0528 - accuracy: 0.6681 - val_loss: 0.0584 - val_accuracy: 0.6300\n",
      "Epoch 28/300\n",
      "1199/1199 [==============================] - 0s 47us/step - loss: 0.0532 - accuracy: 0.6647 - val_loss: 0.0589 - val_accuracy: 0.6400\n",
      "Epoch 29/300\n",
      "1199/1199 [==============================] - 0s 49us/step - loss: 0.0529 - accuracy: 0.6589 - val_loss: 0.0587 - val_accuracy: 0.6325\n",
      "Epoch 30/300\n",
      "1199/1199 [==============================] - 0s 46us/step - loss: 0.0519 - accuracy: 0.6764 - val_loss: 0.0582 - val_accuracy: 0.6300\n",
      "Epoch 31/300\n",
      "1199/1199 [==============================] - 0s 49us/step - loss: 0.0513 - accuracy: 0.6772 - val_loss: 0.0585 - val_accuracy: 0.6350\n",
      "Epoch 32/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0522 - accuracy: 0.6756 - val_loss: 0.0583 - val_accuracy: 0.6350\n",
      "Epoch 33/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0514 - accuracy: 0.6806 - val_loss: 0.0583 - val_accuracy: 0.6400\n",
      "Epoch 34/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0521 - accuracy: 0.6739 - val_loss: 0.0581 - val_accuracy: 0.6325\n",
      "Epoch 35/300\n",
      "1199/1199 [==============================] - 0s 48us/step - loss: 0.0513 - accuracy: 0.6756 - val_loss: 0.0584 - val_accuracy: 0.6325\n",
      "Epoch 36/300\n",
      "1199/1199 [==============================] - 0s 48us/step - loss: 0.0505 - accuracy: 0.6772 - val_loss: 0.0582 - val_accuracy: 0.6425\n",
      "Epoch 37/300\n",
      "1199/1199 [==============================] - 0s 48us/step - loss: 0.0516 - accuracy: 0.6739 - val_loss: 0.0581 - val_accuracy: 0.6275\n",
      "Epoch 38/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0508 - accuracy: 0.6781 - val_loss: 0.0591 - val_accuracy: 0.6350\n",
      "Epoch 39/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0509 - accuracy: 0.6822 - val_loss: 0.0584 - val_accuracy: 0.6300\n",
      "Epoch 40/300\n",
      "1199/1199 [==============================] - 0s 62us/step - loss: 0.0506 - accuracy: 0.6822 - val_loss: 0.0581 - val_accuracy: 0.6400\n",
      "Epoch 41/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0512 - accuracy: 0.6781 - val_loss: 0.0588 - val_accuracy: 0.6400\n",
      "Epoch 42/300\n",
      "1199/1199 [==============================] - 0s 80us/step - loss: 0.0501 - accuracy: 0.6906 - val_loss: 0.0584 - val_accuracy: 0.6225\n",
      "Epoch 43/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0504 - accuracy: 0.6847 - val_loss: 0.0582 - val_accuracy: 0.6400\n",
      "Epoch 44/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0500 - accuracy: 0.6864 - val_loss: 0.0585 - val_accuracy: 0.6425\n",
      "Epoch 45/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0497 - accuracy: 0.6781 - val_loss: 0.0583 - val_accuracy: 0.6425\n",
      "Epoch 46/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0494 - accuracy: 0.6989 - val_loss: 0.0588 - val_accuracy: 0.6350\n",
      "Epoch 47/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0489 - accuracy: 0.6989 - val_loss: 0.0583 - val_accuracy: 0.6475\n",
      "Epoch 48/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0490 - accuracy: 0.6906 - val_loss: 0.0582 - val_accuracy: 0.6375\n",
      "Epoch 49/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0485 - accuracy: 0.6981 - val_loss: 0.0579 - val_accuracy: 0.6500\n",
      "Epoch 50/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0488 - accuracy: 0.7014 - val_loss: 0.0578 - val_accuracy: 0.6500\n",
      "Epoch 51/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0484 - accuracy: 0.7064 - val_loss: 0.0580 - val_accuracy: 0.6525\n",
      "Epoch 52/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0487 - accuracy: 0.7106 - val_loss: 0.0578 - val_accuracy: 0.6450\n",
      "Epoch 53/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0477 - accuracy: 0.7056 - val_loss: 0.0582 - val_accuracy: 0.6425\n",
      "Epoch 54/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0471 - accuracy: 0.7214 - val_loss: 0.0577 - val_accuracy: 0.6350\n",
      "Epoch 55/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0480 - accuracy: 0.7006 - val_loss: 0.0577 - val_accuracy: 0.6550\n",
      "Epoch 56/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0469 - accuracy: 0.7139 - val_loss: 0.0575 - val_accuracy: 0.6500\n",
      "Epoch 57/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0471 - accuracy: 0.7073 - val_loss: 0.0578 - val_accuracy: 0.6575\n",
      "Epoch 58/300\n",
      "1199/1199 [==============================] - 0s 70us/step - loss: 0.0466 - accuracy: 0.7106 - val_loss: 0.0576 - val_accuracy: 0.6500\n",
      "Epoch 59/300\n",
      "1199/1199 [==============================] - 0s 61us/step - loss: 0.0465 - accuracy: 0.7164 - val_loss: 0.0585 - val_accuracy: 0.6375\n",
      "Epoch 60/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0461 - accuracy: 0.7181 - val_loss: 0.0576 - val_accuracy: 0.6425\n",
      "Epoch 61/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0464 - accuracy: 0.7131 - val_loss: 0.0575 - val_accuracy: 0.6450\n",
      "Epoch 62/300\n",
      "1199/1199 [==============================] - 0s 66us/step - loss: 0.0468 - accuracy: 0.7173 - val_loss: 0.0578 - val_accuracy: 0.6325\n",
      "Epoch 63/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0464 - accuracy: 0.7089 - val_loss: 0.0575 - val_accuracy: 0.6400\n",
      "Epoch 64/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0460 - accuracy: 0.7198 - val_loss: 0.0575 - val_accuracy: 0.6450\n",
      "Epoch 65/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0463 - accuracy: 0.7198 - val_loss: 0.0578 - val_accuracy: 0.6400\n",
      "Epoch 66/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0461 - accuracy: 0.7131 - val_loss: 0.0577 - val_accuracy: 0.6275\n",
      "Epoch 67/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0464 - accuracy: 0.7181 - val_loss: 0.0576 - val_accuracy: 0.6400\n",
      "Epoch 68/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0452 - accuracy: 0.7181 - val_loss: 0.0578 - val_accuracy: 0.6325\n",
      "Epoch 69/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0458 - accuracy: 0.7256 - val_loss: 0.0582 - val_accuracy: 0.6325\n",
      "Epoch 70/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0445 - accuracy: 0.7331 - val_loss: 0.0583 - val_accuracy: 0.6325\n",
      "Epoch 71/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0453 - accuracy: 0.7248 - val_loss: 0.0583 - val_accuracy: 0.6375\n",
      "Epoch 72/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0441 - accuracy: 0.7415 - val_loss: 0.0582 - val_accuracy: 0.6450\n",
      "Epoch 73/300\n",
      "1199/1199 [==============================] - 0s 58us/step - loss: 0.0439 - accuracy: 0.7331 - val_loss: 0.0582 - val_accuracy: 0.6325\n",
      "Epoch 74/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0446 - accuracy: 0.7364 - val_loss: 0.0585 - val_accuracy: 0.6300\n",
      "Epoch 75/300\n",
      "1199/1199 [==============================] - 0s 59us/step - loss: 0.0438 - accuracy: 0.7298 - val_loss: 0.0580 - val_accuracy: 0.6425\n",
      "Epoch 76/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0438 - accuracy: 0.7373 - val_loss: 0.0583 - val_accuracy: 0.6400\n",
      "Epoch 77/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0438 - accuracy: 0.7415 - val_loss: 0.0581 - val_accuracy: 0.6450\n",
      "Epoch 78/300\n",
      "1199/1199 [==============================] - 0s 58us/step - loss: 0.0441 - accuracy: 0.7314 - val_loss: 0.0583 - val_accuracy: 0.6450\n",
      "Epoch 79/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0437 - accuracy: 0.7356 - val_loss: 0.0587 - val_accuracy: 0.6500\n",
      "Epoch 80/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0435 - accuracy: 0.7440 - val_loss: 0.0589 - val_accuracy: 0.6375\n",
      "Epoch 81/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0427 - accuracy: 0.7515 - val_loss: 0.0583 - val_accuracy: 0.6425\n",
      "Epoch 82/300\n",
      "1199/1199 [==============================] - 0s 61us/step - loss: 0.0437 - accuracy: 0.7448 - val_loss: 0.0584 - val_accuracy: 0.6425\n",
      "Epoch 83/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0430 - accuracy: 0.7456 - val_loss: 0.0582 - val_accuracy: 0.6400\n",
      "Epoch 84/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0428 - accuracy: 0.7506 - val_loss: 0.0584 - val_accuracy: 0.6425\n",
      "Epoch 85/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0431 - accuracy: 0.7398 - val_loss: 0.0580 - val_accuracy: 0.6525\n",
      "Epoch 86/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0430 - accuracy: 0.7398 - val_loss: 0.0582 - val_accuracy: 0.6450\n",
      "Epoch 87/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0421 - accuracy: 0.7498 - val_loss: 0.0583 - val_accuracy: 0.6450\n",
      "Epoch 88/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0416 - accuracy: 0.7423 - val_loss: 0.0587 - val_accuracy: 0.6425\n",
      "Epoch 89/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0426 - accuracy: 0.7348 - val_loss: 0.0586 - val_accuracy: 0.6425\n",
      "Epoch 90/300\n",
      "1199/1199 [==============================] - 0s 48us/step - loss: 0.0420 - accuracy: 0.7623 - val_loss: 0.0585 - val_accuracy: 0.6475\n",
      "Epoch 91/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0417 - accuracy: 0.7565 - val_loss: 0.0582 - val_accuracy: 0.6600\n",
      "Epoch 92/300\n",
      "1199/1199 [==============================] - 0s 58us/step - loss: 0.0418 - accuracy: 0.7465 - val_loss: 0.0580 - val_accuracy: 0.6625\n",
      "Epoch 93/300\n",
      "1199/1199 [==============================] - 0s 49us/step - loss: 0.0422 - accuracy: 0.7573 - val_loss: 0.0581 - val_accuracy: 0.6525\n",
      "Epoch 94/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0415 - accuracy: 0.7498 - val_loss: 0.0583 - val_accuracy: 0.6475\n",
      "Epoch 95/300\n",
      "1199/1199 [==============================] - 0s 49us/step - loss: 0.0409 - accuracy: 0.7565 - val_loss: 0.0578 - val_accuracy: 0.6600\n",
      "Epoch 96/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0413 - accuracy: 0.7531 - val_loss: 0.0586 - val_accuracy: 0.6475\n",
      "Epoch 97/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0406 - accuracy: 0.7648 - val_loss: 0.0581 - val_accuracy: 0.6550\n",
      "Epoch 98/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0404 - accuracy: 0.7573 - val_loss: 0.0584 - val_accuracy: 0.6550\n",
      "Epoch 99/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0409 - accuracy: 0.7565 - val_loss: 0.0583 - val_accuracy: 0.6575\n",
      "Epoch 100/300\n",
      "1199/1199 [==============================] - 0s 62us/step - loss: 0.0403 - accuracy: 0.7656 - val_loss: 0.0583 - val_accuracy: 0.6500\n",
      "Epoch 101/300\n",
      "1199/1199 [==============================] - 0s 58us/step - loss: 0.0411 - accuracy: 0.7590 - val_loss: 0.0581 - val_accuracy: 0.6550\n",
      "Epoch 102/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0406 - accuracy: 0.7623 - val_loss: 0.0586 - val_accuracy: 0.6550\n",
      "Epoch 103/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0403 - accuracy: 0.7631 - val_loss: 0.0586 - val_accuracy: 0.6350\n",
      "Epoch 104/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0409 - accuracy: 0.7548 - val_loss: 0.0581 - val_accuracy: 0.6550\n",
      "Epoch 105/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0410 - accuracy: 0.7631 - val_loss: 0.0589 - val_accuracy: 0.6425\n",
      "Epoch 106/300\n",
      "1199/1199 [==============================] - 0s 66us/step - loss: 0.0399 - accuracy: 0.7615 - val_loss: 0.0588 - val_accuracy: 0.6350\n",
      "Epoch 107/300\n",
      "1199/1199 [==============================] - 0s 61us/step - loss: 0.0410 - accuracy: 0.7556 - val_loss: 0.0583 - val_accuracy: 0.6650\n",
      "Epoch 108/300\n",
      "1199/1199 [==============================] - 0s 65us/step - loss: 0.0388 - accuracy: 0.7773 - val_loss: 0.0584 - val_accuracy: 0.6350\n",
      "Epoch 109/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0396 - accuracy: 0.7673 - val_loss: 0.0586 - val_accuracy: 0.6475\n",
      "Epoch 110/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0400 - accuracy: 0.7606 - val_loss: 0.0587 - val_accuracy: 0.6500\n",
      "Epoch 111/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0391 - accuracy: 0.7740 - val_loss: 0.0586 - val_accuracy: 0.6575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0384 - accuracy: 0.7798 - val_loss: 0.0588 - val_accuracy: 0.6425\n",
      "Epoch 113/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0391 - accuracy: 0.7665 - val_loss: 0.0584 - val_accuracy: 0.6575\n",
      "Epoch 114/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0382 - accuracy: 0.7748 - val_loss: 0.0585 - val_accuracy: 0.6450\n",
      "Epoch 115/300\n",
      "1199/1199 [==============================] - 0s 58us/step - loss: 0.0380 - accuracy: 0.7832 - val_loss: 0.0583 - val_accuracy: 0.6575\n",
      "Epoch 116/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0379 - accuracy: 0.7898 - val_loss: 0.0587 - val_accuracy: 0.6550\n",
      "Epoch 117/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0393 - accuracy: 0.7590 - val_loss: 0.0586 - val_accuracy: 0.6600\n",
      "Epoch 118/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0385 - accuracy: 0.7773 - val_loss: 0.0583 - val_accuracy: 0.6525\n",
      "Epoch 119/300\n",
      "1199/1199 [==============================] - 0s 75us/step - loss: 0.0380 - accuracy: 0.7815 - val_loss: 0.0590 - val_accuracy: 0.6475\n",
      "Epoch 120/300\n",
      "1199/1199 [==============================] - 0s 71us/step - loss: 0.0377 - accuracy: 0.7898 - val_loss: 0.0587 - val_accuracy: 0.6475\n",
      "Epoch 121/300\n",
      "1199/1199 [==============================] - 0s 64us/step - loss: 0.0377 - accuracy: 0.7748 - val_loss: 0.0589 - val_accuracy: 0.6475\n",
      "Epoch 122/300\n",
      "1199/1199 [==============================] - 0s 59us/step - loss: 0.0389 - accuracy: 0.7740 - val_loss: 0.0593 - val_accuracy: 0.6525\n",
      "Epoch 123/300\n",
      "1199/1199 [==============================] - 0s 66us/step - loss: 0.0379 - accuracy: 0.7756 - val_loss: 0.0593 - val_accuracy: 0.6425\n",
      "Epoch 124/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0372 - accuracy: 0.7823 - val_loss: 0.0599 - val_accuracy: 0.6500\n",
      "Epoch 125/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0380 - accuracy: 0.7798 - val_loss: 0.0588 - val_accuracy: 0.6525\n",
      "Epoch 126/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0366 - accuracy: 0.7873 - val_loss: 0.0588 - val_accuracy: 0.6450\n",
      "Epoch 127/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0380 - accuracy: 0.7790 - val_loss: 0.0586 - val_accuracy: 0.6400\n",
      "Epoch 128/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0371 - accuracy: 0.7882 - val_loss: 0.0587 - val_accuracy: 0.6575\n",
      "Epoch 129/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0363 - accuracy: 0.7890 - val_loss: 0.0593 - val_accuracy: 0.6500\n",
      "Epoch 130/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0366 - accuracy: 0.7807 - val_loss: 0.0593 - val_accuracy: 0.6475\n",
      "Epoch 131/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0377 - accuracy: 0.7765 - val_loss: 0.0595 - val_accuracy: 0.6425\n",
      "Epoch 132/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0370 - accuracy: 0.7898 - val_loss: 0.0593 - val_accuracy: 0.6550\n",
      "Epoch 133/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0360 - accuracy: 0.7907 - val_loss: 0.0590 - val_accuracy: 0.6475\n",
      "Epoch 134/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0367 - accuracy: 0.7948 - val_loss: 0.0584 - val_accuracy: 0.6525\n",
      "Epoch 135/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0364 - accuracy: 0.7832 - val_loss: 0.0591 - val_accuracy: 0.6450\n",
      "Epoch 136/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0374 - accuracy: 0.7840 - val_loss: 0.0589 - val_accuracy: 0.6325\n",
      "Epoch 137/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0366 - accuracy: 0.7898 - val_loss: 0.0586 - val_accuracy: 0.6400\n",
      "Epoch 138/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0370 - accuracy: 0.7898 - val_loss: 0.0589 - val_accuracy: 0.6475\n",
      "Epoch 139/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0367 - accuracy: 0.7898 - val_loss: 0.0591 - val_accuracy: 0.6450\n",
      "Epoch 140/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0365 - accuracy: 0.7940 - val_loss: 0.0593 - val_accuracy: 0.6275\n",
      "Epoch 141/300\n",
      "1199/1199 [==============================] - 0s 59us/step - loss: 0.0358 - accuracy: 0.7882 - val_loss: 0.0594 - val_accuracy: 0.6350\n",
      "Epoch 142/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0358 - accuracy: 0.7982 - val_loss: 0.0600 - val_accuracy: 0.6225\n",
      "Epoch 143/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0353 - accuracy: 0.8065 - val_loss: 0.0591 - val_accuracy: 0.6475\n",
      "Epoch 144/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0360 - accuracy: 0.7998 - val_loss: 0.0600 - val_accuracy: 0.6400\n",
      "Epoch 145/300\n",
      "1199/1199 [==============================] - 0s 58us/step - loss: 0.0356 - accuracy: 0.7998 - val_loss: 0.0598 - val_accuracy: 0.6275\n",
      "Epoch 146/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0353 - accuracy: 0.7915 - val_loss: 0.0596 - val_accuracy: 0.6400\n",
      "Epoch 147/300\n",
      "1199/1199 [==============================] - 0s 49us/step - loss: 0.0358 - accuracy: 0.7948 - val_loss: 0.0591 - val_accuracy: 0.6225\n",
      "Epoch 148/300\n",
      "1199/1199 [==============================] - 0s 59us/step - loss: 0.0344 - accuracy: 0.8057 - val_loss: 0.0592 - val_accuracy: 0.6475\n",
      "Epoch 149/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0357 - accuracy: 0.7965 - val_loss: 0.0593 - val_accuracy: 0.6150\n",
      "Epoch 150/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0348 - accuracy: 0.8048 - val_loss: 0.0589 - val_accuracy: 0.6450\n",
      "Epoch 151/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0351 - accuracy: 0.7915 - val_loss: 0.0599 - val_accuracy: 0.6275\n",
      "Epoch 152/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0350 - accuracy: 0.8098 - val_loss: 0.0592 - val_accuracy: 0.6350\n",
      "Epoch 153/300\n",
      "1199/1199 [==============================] - 0s 47us/step - loss: 0.0342 - accuracy: 0.8032 - val_loss: 0.0585 - val_accuracy: 0.6425\n",
      "Epoch 154/300\n",
      "1199/1199 [==============================] - 0s 47us/step - loss: 0.0337 - accuracy: 0.8082 - val_loss: 0.0591 - val_accuracy: 0.6325\n",
      "Epoch 155/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0343 - accuracy: 0.8090 - val_loss: 0.0591 - val_accuracy: 0.6400\n",
      "Epoch 156/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0341 - accuracy: 0.8132 - val_loss: 0.0595 - val_accuracy: 0.6425\n",
      "Epoch 157/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0332 - accuracy: 0.8132 - val_loss: 0.0594 - val_accuracy: 0.6375\n",
      "Epoch 158/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0344 - accuracy: 0.8048 - val_loss: 0.0594 - val_accuracy: 0.6400\n",
      "Epoch 159/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0343 - accuracy: 0.8065 - val_loss: 0.0598 - val_accuracy: 0.6475\n",
      "Epoch 160/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0336 - accuracy: 0.8165 - val_loss: 0.0592 - val_accuracy: 0.6400\n",
      "Epoch 161/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0350 - accuracy: 0.8015 - val_loss: 0.0599 - val_accuracy: 0.6375\n",
      "Epoch 162/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0341 - accuracy: 0.8040 - val_loss: 0.0588 - val_accuracy: 0.6450\n",
      "Epoch 163/300\n",
      "1199/1199 [==============================] - 0s 58us/step - loss: 0.0347 - accuracy: 0.8065 - val_loss: 0.0595 - val_accuracy: 0.6350\n",
      "Epoch 164/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0330 - accuracy: 0.8198 - val_loss: 0.0599 - val_accuracy: 0.6225\n",
      "Epoch 165/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0331 - accuracy: 0.8190 - val_loss: 0.0590 - val_accuracy: 0.6400\n",
      "Epoch 166/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0339 - accuracy: 0.8073 - val_loss: 0.0596 - val_accuracy: 0.6350\n",
      "Epoch 167/300\n",
      "1199/1199 [==============================] - 0s 72us/step - loss: 0.0343 - accuracy: 0.7965 - val_loss: 0.0597 - val_accuracy: 0.6375\n",
      "Epoch 168/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0326 - accuracy: 0.8207 - val_loss: 0.0603 - val_accuracy: 0.6250\n",
      "Epoch 169/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0326 - accuracy: 0.8173 - val_loss: 0.0592 - val_accuracy: 0.6450\n",
      "Epoch 170/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0325 - accuracy: 0.8232 - val_loss: 0.0603 - val_accuracy: 0.6325\n",
      "Epoch 171/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0331 - accuracy: 0.8082 - val_loss: 0.0598 - val_accuracy: 0.6350\n",
      "Epoch 172/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0322 - accuracy: 0.8173 - val_loss: 0.0599 - val_accuracy: 0.6400\n",
      "Epoch 173/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0330 - accuracy: 0.8190 - val_loss: 0.0598 - val_accuracy: 0.6300\n",
      "Epoch 174/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0318 - accuracy: 0.8307 - val_loss: 0.0592 - val_accuracy: 0.6375\n",
      "Epoch 175/300\n",
      "1199/1199 [==============================] - 0s 60us/step - loss: 0.0318 - accuracy: 0.8140 - val_loss: 0.0598 - val_accuracy: 0.6275\n",
      "Epoch 176/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0313 - accuracy: 0.8307 - val_loss: 0.0594 - val_accuracy: 0.6425\n",
      "Epoch 177/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0331 - accuracy: 0.8132 - val_loss: 0.0588 - val_accuracy: 0.6475\n",
      "Epoch 178/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0322 - accuracy: 0.8232 - val_loss: 0.0599 - val_accuracy: 0.6300\n",
      "Epoch 179/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0328 - accuracy: 0.8148 - val_loss: 0.0590 - val_accuracy: 0.6325\n",
      "Epoch 180/300\n",
      "1199/1199 [==============================] - 0s 58us/step - loss: 0.0317 - accuracy: 0.8290 - val_loss: 0.0593 - val_accuracy: 0.6350\n",
      "Epoch 181/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0323 - accuracy: 0.8173 - val_loss: 0.0598 - val_accuracy: 0.6375\n",
      "Epoch 182/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0317 - accuracy: 0.8265 - val_loss: 0.0590 - val_accuracy: 0.6425\n",
      "Epoch 183/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0299 - accuracy: 0.8449 - val_loss: 0.0592 - val_accuracy: 0.6525\n",
      "Epoch 184/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0323 - accuracy: 0.8140 - val_loss: 0.0583 - val_accuracy: 0.6575\n",
      "Epoch 185/300\n",
      "1199/1199 [==============================] - 0s 59us/step - loss: 0.0313 - accuracy: 0.8332 - val_loss: 0.0584 - val_accuracy: 0.6425\n",
      "Epoch 186/300\n",
      "1199/1199 [==============================] - 0s 62us/step - loss: 0.0313 - accuracy: 0.8257 - val_loss: 0.0594 - val_accuracy: 0.6550\n",
      "Epoch 187/300\n",
      "1199/1199 [==============================] - 0s 72us/step - loss: 0.0313 - accuracy: 0.8265 - val_loss: 0.0599 - val_accuracy: 0.6375\n",
      "Epoch 188/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0314 - accuracy: 0.8232 - val_loss: 0.0597 - val_accuracy: 0.6425\n",
      "Epoch 189/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0311 - accuracy: 0.8207 - val_loss: 0.0596 - val_accuracy: 0.6500\n",
      "Epoch 190/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0307 - accuracy: 0.8332 - val_loss: 0.0597 - val_accuracy: 0.6400\n",
      "Epoch 191/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0305 - accuracy: 0.8282 - val_loss: 0.0599 - val_accuracy: 0.6600\n",
      "Epoch 192/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0303 - accuracy: 0.8357 - val_loss: 0.0591 - val_accuracy: 0.6550\n",
      "Epoch 193/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0307 - accuracy: 0.8374 - val_loss: 0.0593 - val_accuracy: 0.6550\n",
      "Epoch 194/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0311 - accuracy: 0.8249 - val_loss: 0.0594 - val_accuracy: 0.6550\n",
      "Epoch 195/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0312 - accuracy: 0.8215 - val_loss: 0.0600 - val_accuracy: 0.6475\n",
      "Epoch 196/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0315 - accuracy: 0.8265 - val_loss: 0.0596 - val_accuracy: 0.6525\n",
      "Epoch 197/300\n",
      "1199/1199 [==============================] - 0s 47us/step - loss: 0.0299 - accuracy: 0.8307 - val_loss: 0.0598 - val_accuracy: 0.6475\n",
      "Epoch 198/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0306 - accuracy: 0.8307 - val_loss: 0.0602 - val_accuracy: 0.6475\n",
      "Epoch 199/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0297 - accuracy: 0.8340 - val_loss: 0.0593 - val_accuracy: 0.6550\n",
      "Epoch 200/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0298 - accuracy: 0.8365 - val_loss: 0.0602 - val_accuracy: 0.6500\n",
      "Epoch 201/300\n",
      "1199/1199 [==============================] - 0s 49us/step - loss: 0.0303 - accuracy: 0.8307 - val_loss: 0.0593 - val_accuracy: 0.6475\n",
      "Epoch 202/300\n",
      "1199/1199 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.81 - 0s 52us/step - loss: 0.0301 - accuracy: 0.8382 - val_loss: 0.0591 - val_accuracy: 0.6600\n",
      "Epoch 203/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0293 - accuracy: 0.8357 - val_loss: 0.0596 - val_accuracy: 0.6575\n",
      "Epoch 204/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0286 - accuracy: 0.8440 - val_loss: 0.0608 - val_accuracy: 0.6400\n",
      "Epoch 205/300\n",
      "1199/1199 [==============================] - 0s 59us/step - loss: 0.0301 - accuracy: 0.8315 - val_loss: 0.0596 - val_accuracy: 0.6550\n",
      "Epoch 206/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0286 - accuracy: 0.8424 - val_loss: 0.0601 - val_accuracy: 0.6425\n",
      "Epoch 207/300\n",
      "1199/1199 [==============================] - 0s 58us/step - loss: 0.0301 - accuracy: 0.8357 - val_loss: 0.0599 - val_accuracy: 0.6400\n",
      "Epoch 208/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0306 - accuracy: 0.8382 - val_loss: 0.0594 - val_accuracy: 0.6550\n",
      "Epoch 209/300\n",
      "1199/1199 [==============================] - 0s 49us/step - loss: 0.0292 - accuracy: 0.8382 - val_loss: 0.0603 - val_accuracy: 0.6425\n",
      "Epoch 210/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0303 - accuracy: 0.8307 - val_loss: 0.0606 - val_accuracy: 0.6425\n",
      "Epoch 211/300\n",
      "1199/1199 [==============================] - 0s 47us/step - loss: 0.0300 - accuracy: 0.8440 - val_loss: 0.0597 - val_accuracy: 0.6475\n",
      "Epoch 212/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0301 - accuracy: 0.8315 - val_loss: 0.0594 - val_accuracy: 0.6475\n",
      "Epoch 213/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0294 - accuracy: 0.8382 - val_loss: 0.0611 - val_accuracy: 0.6450\n",
      "Epoch 214/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0300 - accuracy: 0.8365 - val_loss: 0.0609 - val_accuracy: 0.6450\n",
      "Epoch 215/300\n",
      "1199/1199 [==============================] - 0s 58us/step - loss: 0.0285 - accuracy: 0.8482 - val_loss: 0.0599 - val_accuracy: 0.6475\n",
      "Epoch 216/300\n",
      "1199/1199 [==============================] - 0s 49us/step - loss: 0.0296 - accuracy: 0.8324 - val_loss: 0.0602 - val_accuracy: 0.6425\n",
      "Epoch 217/300\n",
      "1199/1199 [==============================] - 0s 47us/step - loss: 0.0293 - accuracy: 0.8374 - val_loss: 0.0602 - val_accuracy: 0.6550\n",
      "Epoch 218/300\n",
      "1199/1199 [==============================] - 0s 50us/step - loss: 0.0293 - accuracy: 0.8432 - val_loss: 0.0598 - val_accuracy: 0.6450\n",
      "Epoch 219/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0283 - accuracy: 0.8432 - val_loss: 0.0601 - val_accuracy: 0.6550\n",
      "Epoch 220/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0285 - accuracy: 0.8457 - val_loss: 0.0588 - val_accuracy: 0.6525\n",
      "Epoch 221/300\n",
      "1199/1199 [==============================] - 0s 66us/step - loss: 0.0272 - accuracy: 0.8549 - val_loss: 0.0595 - val_accuracy: 0.6625\n",
      "Epoch 222/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1199/1199 [==============================] - 0s 64us/step - loss: 0.0275 - accuracy: 0.8549 - val_loss: 0.0595 - val_accuracy: 0.6425\n",
      "Epoch 223/300\n",
      "1199/1199 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.76 - 0s 54us/step - loss: 0.0288 - accuracy: 0.8432 - val_loss: 0.0594 - val_accuracy: 0.6675\n",
      "Epoch 224/300\n",
      "1199/1199 [==============================] - 0s 59us/step - loss: 0.0282 - accuracy: 0.8424 - val_loss: 0.0596 - val_accuracy: 0.6525\n",
      "Epoch 225/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0284 - accuracy: 0.8574 - val_loss: 0.0596 - val_accuracy: 0.6550\n",
      "Epoch 226/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0279 - accuracy: 0.8549 - val_loss: 0.0593 - val_accuracy: 0.6575\n",
      "Epoch 227/300\n",
      "1199/1199 [==============================] - 0s 58us/step - loss: 0.0289 - accuracy: 0.8357 - val_loss: 0.0594 - val_accuracy: 0.6700\n",
      "Epoch 228/300\n",
      "1199/1199 [==============================] - 0s 48us/step - loss: 0.0283 - accuracy: 0.8432 - val_loss: 0.0600 - val_accuracy: 0.6550\n",
      "Epoch 229/300\n",
      "1199/1199 [==============================] - 0s 62us/step - loss: 0.0281 - accuracy: 0.8540 - val_loss: 0.0599 - val_accuracy: 0.6625\n",
      "Epoch 230/300\n",
      "1199/1199 [==============================] - 0s 63us/step - loss: 0.0273 - accuracy: 0.8549 - val_loss: 0.0597 - val_accuracy: 0.6650\n",
      "Epoch 231/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0277 - accuracy: 0.8440 - val_loss: 0.0611 - val_accuracy: 0.6450\n",
      "Epoch 232/300\n",
      "1199/1199 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.84 - 0s 69us/step - loss: 0.0280 - accuracy: 0.8457 - val_loss: 0.0593 - val_accuracy: 0.6550\n",
      "Epoch 233/300\n",
      "1199/1199 [==============================] - 0s 68us/step - loss: 0.0296 - accuracy: 0.8349 - val_loss: 0.0597 - val_accuracy: 0.6575\n",
      "Epoch 234/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0285 - accuracy: 0.8499 - val_loss: 0.0594 - val_accuracy: 0.6675\n",
      "Epoch 235/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0279 - accuracy: 0.8515 - val_loss: 0.0589 - val_accuracy: 0.6650\n",
      "Epoch 236/300\n",
      "1199/1199 [==============================] - 0s 60us/step - loss: 0.0279 - accuracy: 0.8474 - val_loss: 0.0601 - val_accuracy: 0.6550\n",
      "Epoch 237/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0274 - accuracy: 0.8574 - val_loss: 0.0596 - val_accuracy: 0.6600\n",
      "Epoch 238/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0276 - accuracy: 0.8574 - val_loss: 0.0594 - val_accuracy: 0.6650\n",
      "Epoch 239/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0273 - accuracy: 0.8549 - val_loss: 0.0596 - val_accuracy: 0.6575\n",
      "Epoch 240/300\n",
      "1199/1199 [==============================] - 0s 65us/step - loss: 0.0269 - accuracy: 0.8574 - val_loss: 0.0601 - val_accuracy: 0.6650\n",
      "Epoch 241/300\n",
      "1199/1199 [==============================] - 0s 64us/step - loss: 0.0264 - accuracy: 0.8607 - val_loss: 0.0589 - val_accuracy: 0.6575\n",
      "Epoch 242/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0261 - accuracy: 0.8691 - val_loss: 0.0590 - val_accuracy: 0.6650\n",
      "Epoch 243/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0267 - accuracy: 0.8599 - val_loss: 0.0603 - val_accuracy: 0.6575\n",
      "Epoch 244/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0276 - accuracy: 0.8532 - val_loss: 0.0598 - val_accuracy: 0.6475\n",
      "Epoch 245/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0263 - accuracy: 0.8557 - val_loss: 0.0599 - val_accuracy: 0.6675\n",
      "Epoch 246/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0268 - accuracy: 0.8582 - val_loss: 0.0604 - val_accuracy: 0.6550\n",
      "Epoch 247/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0263 - accuracy: 0.8682 - val_loss: 0.0595 - val_accuracy: 0.6500\n",
      "Epoch 248/300\n",
      "1199/1199 [==============================] - 0s 58us/step - loss: 0.0268 - accuracy: 0.8524 - val_loss: 0.0600 - val_accuracy: 0.6525\n",
      "Epoch 249/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0273 - accuracy: 0.8565 - val_loss: 0.0593 - val_accuracy: 0.6675\n",
      "Epoch 250/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0273 - accuracy: 0.8532 - val_loss: 0.0598 - val_accuracy: 0.6575\n",
      "Epoch 251/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0270 - accuracy: 0.8507 - val_loss: 0.0609 - val_accuracy: 0.6500\n",
      "Epoch 252/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0269 - accuracy: 0.8590 - val_loss: 0.0594 - val_accuracy: 0.6575\n",
      "Epoch 253/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0259 - accuracy: 0.8707 - val_loss: 0.0605 - val_accuracy: 0.6575\n",
      "Epoch 254/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0266 - accuracy: 0.8565 - val_loss: 0.0599 - val_accuracy: 0.6650\n",
      "Epoch 255/300\n",
      "1199/1199 [==============================] - 0s 70us/step - loss: 0.0264 - accuracy: 0.8582 - val_loss: 0.0602 - val_accuracy: 0.6600\n",
      "Epoch 256/300\n",
      "1199/1199 [==============================] - 0s 59us/step - loss: 0.0268 - accuracy: 0.8457 - val_loss: 0.0595 - val_accuracy: 0.6550\n",
      "Epoch 257/300\n",
      "1199/1199 [==============================] - 0s 66us/step - loss: 0.0255 - accuracy: 0.8607 - val_loss: 0.0598 - val_accuracy: 0.6675\n",
      "Epoch 258/300\n",
      "1199/1199 [==============================] - 0s 80us/step - loss: 0.0265 - accuracy: 0.8632 - val_loss: 0.0596 - val_accuracy: 0.6600\n",
      "Epoch 259/300\n",
      "1199/1199 [==============================] - 0s 63us/step - loss: 0.0262 - accuracy: 0.8649 - val_loss: 0.0596 - val_accuracy: 0.6550\n",
      "Epoch 260/300\n",
      "1199/1199 [==============================] - 0s 43us/step - loss: 0.0263 - accuracy: 0.8524 - val_loss: 0.0593 - val_accuracy: 0.6625\n",
      "Epoch 261/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0257 - accuracy: 0.8632 - val_loss: 0.0594 - val_accuracy: 0.6575\n",
      "Epoch 262/300\n",
      "1199/1199 [==============================] - 0s 64us/step - loss: 0.0258 - accuracy: 0.8607 - val_loss: 0.0596 - val_accuracy: 0.6525\n",
      "Epoch 263/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0265 - accuracy: 0.8524 - val_loss: 0.0611 - val_accuracy: 0.6525\n",
      "Epoch 264/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0264 - accuracy: 0.8599 - val_loss: 0.0594 - val_accuracy: 0.6625\n",
      "Epoch 265/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0256 - accuracy: 0.8641 - val_loss: 0.0595 - val_accuracy: 0.6525\n",
      "Epoch 266/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0256 - accuracy: 0.8682 - val_loss: 0.0593 - val_accuracy: 0.6575\n",
      "Epoch 267/300\n",
      "1199/1199 [==============================] - 0s 66us/step - loss: 0.0261 - accuracy: 0.8574 - val_loss: 0.0591 - val_accuracy: 0.6600\n",
      "Epoch 268/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0266 - accuracy: 0.8540 - val_loss: 0.0601 - val_accuracy: 0.6600\n",
      "Epoch 269/300\n",
      "1199/1199 [==============================] - 0s 63us/step - loss: 0.0258 - accuracy: 0.8590 - val_loss: 0.0595 - val_accuracy: 0.6625\n",
      "Epoch 270/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0251 - accuracy: 0.8732 - val_loss: 0.0590 - val_accuracy: 0.6575\n",
      "Epoch 271/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0255 - accuracy: 0.8666 - val_loss: 0.0593 - val_accuracy: 0.6625\n",
      "Epoch 272/300\n",
      "1199/1199 [==============================] - 0s 58us/step - loss: 0.0247 - accuracy: 0.8741 - val_loss: 0.0594 - val_accuracy: 0.6450\n",
      "Epoch 273/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0253 - accuracy: 0.8691 - val_loss: 0.0599 - val_accuracy: 0.6450\n",
      "Epoch 274/300\n",
      "1199/1199 [==============================] - 0s 54us/step - loss: 0.0259 - accuracy: 0.8565 - val_loss: 0.0594 - val_accuracy: 0.6550\n",
      "Epoch 275/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0259 - accuracy: 0.8574 - val_loss: 0.0601 - val_accuracy: 0.6575\n",
      "Epoch 276/300\n",
      "1199/1199 [==============================] - 0s 52us/step - loss: 0.0258 - accuracy: 0.8649 - val_loss: 0.0596 - val_accuracy: 0.6575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0252 - accuracy: 0.8674 - val_loss: 0.0599 - val_accuracy: 0.6600\n",
      "Epoch 278/300\n",
      "1199/1199 [==============================] - 0s 58us/step - loss: 0.0249 - accuracy: 0.8749 - val_loss: 0.0595 - val_accuracy: 0.6625\n",
      "Epoch 279/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0252 - accuracy: 0.8774 - val_loss: 0.0604 - val_accuracy: 0.6625\n",
      "Epoch 280/300\n",
      "1199/1199 [==============================] - 0s 65us/step - loss: 0.0248 - accuracy: 0.8682 - val_loss: 0.0594 - val_accuracy: 0.6700\n",
      "Epoch 281/300\n",
      "1199/1199 [==============================] - 0s 63us/step - loss: 0.0250 - accuracy: 0.8682 - val_loss: 0.0604 - val_accuracy: 0.6650\n",
      "Epoch 282/300\n",
      "1199/1199 [==============================] - 0s 67us/step - loss: 0.0238 - accuracy: 0.8707 - val_loss: 0.0608 - val_accuracy: 0.6475\n",
      "Epoch 283/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0244 - accuracy: 0.8741 - val_loss: 0.0604 - val_accuracy: 0.6550\n",
      "Epoch 284/300\n",
      "1199/1199 [==============================] - 0s 59us/step - loss: 0.0239 - accuracy: 0.8774 - val_loss: 0.0600 - val_accuracy: 0.6575\n",
      "Epoch 285/300\n",
      "1199/1199 [==============================] - 0s 59us/step - loss: 0.0242 - accuracy: 0.8699 - val_loss: 0.0604 - val_accuracy: 0.6575\n",
      "Epoch 286/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0243 - accuracy: 0.8774 - val_loss: 0.0605 - val_accuracy: 0.6500\n",
      "Epoch 287/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0245 - accuracy: 0.8674 - val_loss: 0.0610 - val_accuracy: 0.6575\n",
      "Epoch 288/300\n",
      "1199/1199 [==============================] - 0s 62us/step - loss: 0.0249 - accuracy: 0.8666 - val_loss: 0.0596 - val_accuracy: 0.6650\n",
      "Epoch 289/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0245 - accuracy: 0.8732 - val_loss: 0.0603 - val_accuracy: 0.6625\n",
      "Epoch 290/300\n",
      "1199/1199 [==============================] - 0s 58us/step - loss: 0.0249 - accuracy: 0.8657 - val_loss: 0.0597 - val_accuracy: 0.6625\n",
      "Epoch 291/300\n",
      "1199/1199 [==============================] - 0s 51us/step - loss: 0.0243 - accuracy: 0.8674 - val_loss: 0.0606 - val_accuracy: 0.6525\n",
      "Epoch 292/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0250 - accuracy: 0.8565 - val_loss: 0.0604 - val_accuracy: 0.6425\n",
      "Epoch 293/300\n",
      "1199/1199 [==============================] - 0s 72us/step - loss: 0.0252 - accuracy: 0.8632 - val_loss: 0.0601 - val_accuracy: 0.6575\n",
      "Epoch 294/300\n",
      "1199/1199 [==============================] - 0s 57us/step - loss: 0.0248 - accuracy: 0.8666 - val_loss: 0.0598 - val_accuracy: 0.6625\n",
      "Epoch 295/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0240 - accuracy: 0.8791 - val_loss: 0.0599 - val_accuracy: 0.6625\n",
      "Epoch 296/300\n",
      "1199/1199 [==============================] - 0s 53us/step - loss: 0.0243 - accuracy: 0.8691 - val_loss: 0.0598 - val_accuracy: 0.6700\n",
      "Epoch 297/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0250 - accuracy: 0.8666 - val_loss: 0.0595 - val_accuracy: 0.6800\n",
      "Epoch 298/300\n",
      "1199/1199 [==============================] - 0s 55us/step - loss: 0.0239 - accuracy: 0.8757 - val_loss: 0.0592 - val_accuracy: 0.6700\n",
      "Epoch 299/300\n",
      "1199/1199 [==============================] - 0s 47us/step - loss: 0.0240 - accuracy: 0.8749 - val_loss: 0.0590 - val_accuracy: 0.6675\n",
      "Epoch 300/300\n",
      "1199/1199 [==============================] - 0s 56us/step - loss: 0.0240 - accuracy: 0.8757 - val_loss: 0.0594 - val_accuracy: 0.6775\n"
     ]
    }
   ],
   "source": [
    "# Fit (train) the model\n",
    "epochs=100\n",
    "batch_size=100\n",
    "model_history = model.fit(\n",
    "    X_train_scaled, y_train_categorical,\n",
    "    epochs=epochs, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test_scaled, y_test_categorical)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Learning History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# http://localhost:8888/notebooks/DABC_hw/machine-learning-challenge/model_1.ipynb\n",
    "\n",
    "# Plot the loss function\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(model_history.history['loss']), 'r', label='train')\n",
    "ax.plot(np.sqrt(model_history.history['val_loss']), 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "# Plot the accuracy\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(model_history.history['accuracy']), 'r', label='train')\n",
    "ax.plot(np.sqrt(model_history.history['val_accuracy']), 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Accuracy', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 100)               1200      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 9)                 909       \n",
      "=================================================================\n",
      "Total params: 12,209\n",
      "Trainable params: 12,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Training Data Score: {model2.score(X_train_scaled, y_train)}\")\n",
    "# print(f\"Testing Data Score: {model2.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quantifying the Model\n",
    "We use our testing data to validate our model. This is how we determine the validity of our model (i.e. the ability to predict new and previously unseen data points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-715f0369813d2b84",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.059372124075889585, Accuracy: 0.6775000095367432\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the testing data\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.103</td>\n",
       "      <td>32.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99586</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1552            6.3              0.68         0.01             3.7      0.103   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "1552                 32.0                  54.0  0.99586  3.51       0.66   \n",
       "\n",
       "      alcohol  \n",
       "1552     11.3  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions with new data\n",
    "\n",
    "We can use our trained model to make predictions using `model.predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.39629552,  0.90935864, -1.46682535,  1.43746168,  0.93689428,\n",
       "         1.42470036,  0.5660564 ,  0.        ,  1.2709058 ,  0.25985935,\n",
       "         0.97826356]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# test = np.expand_dims(X_test[:1], axis=0)\n",
    "test = X_test_scaled[:1]\n",
    "test.shape\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.asarray(test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: [6]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_classes(test)\n",
    "print(f\"Predicted class: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# label_encoder.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict_classes(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 1)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  predictions\n",
       "0         6            6\n",
       "1         6            6\n",
       "2         5            5\n",
       "3         6            6\n",
       "4         6            6\n",
       "..      ...          ...\n",
       "395       6            6\n",
       "396       6            6\n",
       "397       4            6\n",
       "398       5            5\n",
       "399       6            7\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts_df = pd.DataFrame(columns=[\"y_test\", \"predictions\"])\n",
    "predicts_df['predictions'] = predictions\n",
    "predicts_df['y_test'] = y_test\n",
    "predicts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.50      0.07      0.12        15\n",
      "           5       0.74      0.76      0.75       169\n",
      "           6       0.60      0.75      0.67       149\n",
      "           7       0.79      0.50      0.61        60\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.68       400\n",
      "   macro avg       0.44      0.35      0.36       400\n",
      "weighted avg       0.67      0.68      0.66       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimco\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blogs.oracle.com/meena/simple-neural-network-model-using-keras-and-grid-search-hyperparameterstuning\n",
    "# use KerasClassifier to create a tensor model that is searchable by scikit GridSearchSV\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "gridModel = KerasClassifier(build_fn=create_model, batch_size=50, epochs=10, metrics='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are some parameters that can be varied\n",
    "##def create_model (activation='relu', dropout_rate=0.2, hidden_units=100, \n",
    "##                  optimizer='adam', loss='categorical_crossentropy'):\n",
    "\n",
    "## Potential parameters\n",
    "activation = ['relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "momentum = [0.0,0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "learn_rate = [0.001, 0.01, 0.2, 0.3]\n",
    "dropout_rate=[0.0, 0.1, 0.2, 0.3]\n",
    "weight_contraint=[1,2,3,4,5]\n",
    "\n",
    "hidden_nodes=[10,50,100,200]\n",
    "init= ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', \n",
    "       'he_normal', 'he_uniform']\n",
    "\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "epochs = [100, 200, 500]\n",
    "batch_size = [50, 100, 250, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': [100, 200, 500],\n",
       " 'batch_size': [50, 100, 250, 500],\n",
       " 'dropout_rate': [0.0, 0.1, 0.2, 0.3]}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = dict(epochs=epochs, batch_size=batch_size, dropout_rate=dropout_rate)\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=gridModel, param_grid=param_grid, n_jobs=-1)\n",
    "                    #verbose=1, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimco\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\jimco\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1199/1199 [==============================] - 1s 755us/step - loss: 0.0994 - accuracy: 0.1401\n",
      "Epoch 2/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0948 - accuracy: 0.3328\n",
      "Epoch 3/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0896 - accuracy: 0.4454\n",
      "Epoch 4/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0840 - accuracy: 0.4679\n",
      "Epoch 5/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0793 - accuracy: 0.4746\n",
      "Epoch 6/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0750 - accuracy: 0.4962\n",
      "Epoch 7/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0715 - accuracy: 0.5021\n",
      "Epoch 8/500\n",
      "1199/1199 [==============================] - 0s 27us/step - loss: 0.0684 - accuracy: 0.5379\n",
      "Epoch 9/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0653 - accuracy: 0.5580\n",
      "Epoch 10/500\n",
      "1199/1199 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.56 - 0s 21us/step - loss: 0.0640 - accuracy: 0.5738\n",
      "Epoch 11/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0633 - accuracy: 0.5830\n",
      "Epoch 12/500\n",
      "1199/1199 [==============================] - 0s 26us/step - loss: 0.0625 - accuracy: 0.5746\n",
      "Epoch 13/500\n",
      "1199/1199 [==============================] - 0s 26us/step - loss: 0.0616 - accuracy: 0.5897\n",
      "Epoch 14/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0601 - accuracy: 0.5997\n",
      "Epoch 15/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0602 - accuracy: 0.6005\n",
      "Epoch 16/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0600 - accuracy: 0.6005\n",
      "Epoch 17/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0588 - accuracy: 0.6272\n",
      "Epoch 18/500\n",
      "1199/1199 [==============================] - 0s 27us/step - loss: 0.0588 - accuracy: 0.6155\n",
      "Epoch 19/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0586 - accuracy: 0.6197\n",
      "Epoch 20/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0577 - accuracy: 0.6214\n",
      "Epoch 21/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0581 - accuracy: 0.6230\n",
      "Epoch 22/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0577 - accuracy: 0.6289\n",
      "Epoch 23/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0580 - accuracy: 0.6264\n",
      "Epoch 24/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0573 - accuracy: 0.6205\n",
      "Epoch 25/500\n",
      "1199/1199 [==============================] - 0s 15us/step - loss: 0.0572 - accuracy: 0.6205\n",
      "Epoch 26/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0574 - accuracy: 0.6255\n",
      "Epoch 27/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0570 - accuracy: 0.6339\n",
      "Epoch 28/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0566 - accuracy: 0.6322\n",
      "Epoch 29/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0564 - accuracy: 0.6397\n",
      "Epoch 30/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0564 - accuracy: 0.6430\n",
      "Epoch 31/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0565 - accuracy: 0.6289\n",
      "Epoch 32/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0561 - accuracy: 0.6439\n",
      "Epoch 33/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0560 - accuracy: 0.6430\n",
      "Epoch 34/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0561 - accuracy: 0.6347\n",
      "Epoch 35/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0558 - accuracy: 0.6422\n",
      "Epoch 36/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0558 - accuracy: 0.6430\n",
      "Epoch 37/500\n",
      "1199/1199 [==============================] - 0s 27us/step - loss: 0.0553 - accuracy: 0.6422\n",
      "Epoch 38/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0551 - accuracy: 0.6514\n",
      "Epoch 39/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0554 - accuracy: 0.6464\n",
      "Epoch 40/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0550 - accuracy: 0.6497\n",
      "Epoch 41/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0548 - accuracy: 0.6505\n",
      "Epoch 42/500\n",
      "1199/1199 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.62 - 0s 19us/step - loss: 0.0551 - accuracy: 0.6514\n",
      "Epoch 43/500\n",
      "1199/1199 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.58 - 0s 20us/step - loss: 0.0551 - accuracy: 0.6405\n",
      "Epoch 44/500\n",
      "1199/1199 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.61 - 0s 23us/step - loss: 0.0540 - accuracy: 0.6589\n",
      "Epoch 45/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0544 - accuracy: 0.6505\n",
      "Epoch 46/500\n",
      "1199/1199 [==============================] - 0s 27us/step - loss: 0.0539 - accuracy: 0.6489\n",
      "Epoch 47/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0536 - accuracy: 0.6589\n",
      "Epoch 48/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0546 - accuracy: 0.6430\n",
      "Epoch 49/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0541 - accuracy: 0.6597\n",
      "Epoch 50/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0539 - accuracy: 0.6622\n",
      "Epoch 51/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0537 - accuracy: 0.6681\n",
      "Epoch 52/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0539 - accuracy: 0.6580\n",
      "Epoch 53/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0535 - accuracy: 0.6522\n",
      "Epoch 54/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0537 - accuracy: 0.6555\n",
      "Epoch 55/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0538 - accuracy: 0.6497\n",
      "Epoch 56/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0539 - accuracy: 0.6422\n",
      "Epoch 57/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0528 - accuracy: 0.6614\n",
      "Epoch 58/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0531 - accuracy: 0.6697\n",
      "Epoch 59/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0524 - accuracy: 0.6731\n",
      "Epoch 60/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0530 - accuracy: 0.6614\n",
      "Epoch 61/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0531 - accuracy: 0.6647\n",
      "Epoch 62/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0530 - accuracy: 0.6597\n",
      "Epoch 63/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0534 - accuracy: 0.6589\n",
      "Epoch 64/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0526 - accuracy: 0.6622\n",
      "Epoch 65/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0535 - accuracy: 0.6472\n",
      "Epoch 66/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0530 - accuracy: 0.6631\n",
      "Epoch 67/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0525 - accuracy: 0.6739\n",
      "Epoch 68/500\n",
      "1199/1199 [==============================] - 0s 26us/step - loss: 0.0528 - accuracy: 0.6547\n",
      "Epoch 69/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0524 - accuracy: 0.6656\n",
      "Epoch 70/500\n",
      "1199/1199 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.66 - 0s 18us/step - loss: 0.0515 - accuracy: 0.6747\n",
      "Epoch 71/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0523 - accuracy: 0.6656\n",
      "Epoch 72/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0515 - accuracy: 0.6806\n",
      "Epoch 73/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0514 - accuracy: 0.6756\n",
      "Epoch 74/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0518 - accuracy: 0.6689\n",
      "Epoch 75/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0517 - accuracy: 0.6714\n",
      "Epoch 76/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0519 - accuracy: 0.6722\n",
      "Epoch 77/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0514 - accuracy: 0.6789\n",
      "Epoch 78/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0514 - accuracy: 0.6664\n",
      "Epoch 79/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0509 - accuracy: 0.6772\n",
      "Epoch 80/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0515 - accuracy: 0.6664\n",
      "Epoch 81/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0516 - accuracy: 0.6772\n",
      "Epoch 82/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0511 - accuracy: 0.6839\n",
      "Epoch 83/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0510 - accuracy: 0.6806\n",
      "Epoch 84/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0512 - accuracy: 0.6722\n",
      "Epoch 85/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0501 - accuracy: 0.6906\n",
      "Epoch 86/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0514 - accuracy: 0.6797\n",
      "Epoch 87/500\n",
      "1199/1199 [==============================] - 0s 26us/step - loss: 0.0509 - accuracy: 0.6822\n",
      "Epoch 88/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0506 - accuracy: 0.6931\n",
      "Epoch 89/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0498 - accuracy: 0.6914\n",
      "Epoch 90/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0507 - accuracy: 0.6781\n",
      "Epoch 91/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0512 - accuracy: 0.6689\n",
      "Epoch 92/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0507 - accuracy: 0.6847\n",
      "Epoch 93/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0506 - accuracy: 0.6747\n",
      "Epoch 94/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0500 - accuracy: 0.6897\n",
      "Epoch 95/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0503 - accuracy: 0.6839\n",
      "Epoch 96/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0498 - accuracy: 0.6864\n",
      "Epoch 97/500\n",
      "1199/1199 [==============================] - 0s 26us/step - loss: 0.0491 - accuracy: 0.6939\n",
      "Epoch 98/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0501 - accuracy: 0.6964\n",
      "Epoch 99/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0495 - accuracy: 0.6939\n",
      "Epoch 100/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0490 - accuracy: 0.6981\n",
      "Epoch 101/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0503 - accuracy: 0.6881\n",
      "Epoch 102/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0495 - accuracy: 0.6964\n",
      "Epoch 103/500\n",
      "1199/1199 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.70 - 0s 22us/step - loss: 0.0492 - accuracy: 0.7014\n",
      "Epoch 104/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0494 - accuracy: 0.6831\n",
      "Epoch 105/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0491 - accuracy: 0.6872\n",
      "Epoch 106/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0493 - accuracy: 0.6931\n",
      "Epoch 107/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0491 - accuracy: 0.6972\n",
      "Epoch 108/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0483 - accuracy: 0.7056\n",
      "Epoch 109/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0490 - accuracy: 0.6872\n",
      "Epoch 110/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0484 - accuracy: 0.7031\n",
      "Epoch 111/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0495 - accuracy: 0.6972\n",
      "Epoch 112/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0488 - accuracy: 0.6972\n",
      "Epoch 113/500\n",
      "1199/1199 [==============================] - 0s 26us/step - loss: 0.0483 - accuracy: 0.7048\n",
      "Epoch 114/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0479 - accuracy: 0.7064\n",
      "Epoch 115/500\n",
      "1199/1199 [==============================] - 0s 28us/step - loss: 0.0484 - accuracy: 0.7014\n",
      "Epoch 116/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0490 - accuracy: 0.6939\n",
      "Epoch 117/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0472 - accuracy: 0.7131\n",
      "Epoch 118/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0477 - accuracy: 0.6972\n",
      "Epoch 119/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0472 - accuracy: 0.7073\n",
      "Epoch 120/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0481 - accuracy: 0.7081\n",
      "Epoch 121/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0477 - accuracy: 0.7089\n",
      "Epoch 122/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0481 - accuracy: 0.7073\n",
      "Epoch 123/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0470 - accuracy: 0.7106\n",
      "Epoch 124/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0482 - accuracy: 0.6981\n",
      "Epoch 125/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0477 - accuracy: 0.7073\n",
      "Epoch 126/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0475 - accuracy: 0.7106\n",
      "Epoch 127/500\n",
      "1199/1199 [==============================] - 0s 45us/step - loss: 0.0464 - accuracy: 0.7164\n",
      "Epoch 128/500\n",
      "1199/1199 [==============================] - 0s 30us/step - loss: 0.0464 - accuracy: 0.7189\n",
      "Epoch 129/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0469 - accuracy: 0.7131\n",
      "Epoch 130/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0476 - accuracy: 0.7023\n",
      "Epoch 131/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0471 - accuracy: 0.7173\n",
      "Epoch 132/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0473 - accuracy: 0.7056\n",
      "Epoch 133/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0461 - accuracy: 0.7198\n",
      "Epoch 134/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0467 - accuracy: 0.7214\n",
      "Epoch 135/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0464 - accuracy: 0.7156\n",
      "Epoch 136/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0463 - accuracy: 0.7164\n",
      "Epoch 137/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0467 - accuracy: 0.7131\n",
      "Epoch 138/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0472 - accuracy: 0.7139\n",
      "Epoch 139/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0460 - accuracy: 0.7206\n",
      "Epoch 140/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0456 - accuracy: 0.7214\n",
      "Epoch 141/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0460 - accuracy: 0.7148\n",
      "Epoch 142/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0460 - accuracy: 0.7106\n",
      "Epoch 143/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0461 - accuracy: 0.7148\n",
      "Epoch 144/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0456 - accuracy: 0.7248\n",
      "Epoch 145/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0460 - accuracy: 0.7173\n",
      "Epoch 146/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0468 - accuracy: 0.7231\n",
      "Epoch 147/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0459 - accuracy: 0.7239\n",
      "Epoch 148/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0450 - accuracy: 0.7289\n",
      "Epoch 149/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0456 - accuracy: 0.7239\n",
      "Epoch 150/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0448 - accuracy: 0.7323\n",
      "Epoch 151/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0458 - accuracy: 0.7256\n",
      "Epoch 152/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0453 - accuracy: 0.7281\n",
      "Epoch 153/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0451 - accuracy: 0.7214\n",
      "Epoch 154/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0445 - accuracy: 0.7314\n",
      "Epoch 155/500\n",
      "1199/1199 [==============================] - 0s 16us/step - loss: 0.0452 - accuracy: 0.7156\n",
      "Epoch 156/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0454 - accuracy: 0.7256\n",
      "Epoch 157/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0449 - accuracy: 0.7123\n",
      "Epoch 158/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0463 - accuracy: 0.7114\n",
      "Epoch 159/500\n",
      "1199/1199 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.74 - 0s 22us/step - loss: 0.0445 - accuracy: 0.7331\n",
      "Epoch 160/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0448 - accuracy: 0.7273\n",
      "Epoch 161/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0445 - accuracy: 0.7264\n",
      "Epoch 162/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0453 - accuracy: 0.7173\n",
      "Epoch 163/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0448 - accuracy: 0.7273\n",
      "Epoch 164/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0443 - accuracy: 0.7206\n",
      "Epoch 165/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0442 - accuracy: 0.7348\n",
      "Epoch 166/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0439 - accuracy: 0.7415\n",
      "Epoch 167/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0443 - accuracy: 0.7289\n",
      "Epoch 168/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0445 - accuracy: 0.7306\n",
      "Epoch 169/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0443 - accuracy: 0.7264\n",
      "Epoch 170/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0444 - accuracy: 0.7289\n",
      "Epoch 171/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0440 - accuracy: 0.7364\n",
      "Epoch 172/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0432 - accuracy: 0.7531\n",
      "Epoch 173/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0442 - accuracy: 0.7356\n",
      "Epoch 174/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0442 - accuracy: 0.7348\n",
      "Epoch 175/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0437 - accuracy: 0.7389\n",
      "Epoch 176/500\n",
      "1199/1199 [==============================] - 0s 26us/step - loss: 0.0438 - accuracy: 0.7415\n",
      "Epoch 177/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0438 - accuracy: 0.7306\n",
      "Epoch 178/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0441 - accuracy: 0.7456\n",
      "Epoch 179/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0430 - accuracy: 0.7531\n",
      "Epoch 180/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0433 - accuracy: 0.7314\n",
      "Epoch 181/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0423 - accuracy: 0.7473\n",
      "Epoch 182/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0426 - accuracy: 0.7531\n",
      "Epoch 183/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0429 - accuracy: 0.7456\n",
      "Epoch 184/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0439 - accuracy: 0.7389\n",
      "Epoch 185/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0427 - accuracy: 0.7515\n",
      "Epoch 186/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0431 - accuracy: 0.7423\n",
      "Epoch 187/500\n",
      "1199/1199 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.73 - 0s 24us/step - loss: 0.0432 - accuracy: 0.7331\n",
      "Epoch 188/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0428 - accuracy: 0.7440\n",
      "Epoch 189/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0431 - accuracy: 0.7440\n",
      "Epoch 190/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0425 - accuracy: 0.7506\n",
      "Epoch 191/500\n",
      "1199/1199 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.74 - 0s 24us/step - loss: 0.0423 - accuracy: 0.7456\n",
      "Epoch 192/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0431 - accuracy: 0.7289\n",
      "Epoch 193/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0423 - accuracy: 0.7498\n",
      "Epoch 194/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0426 - accuracy: 0.7448\n",
      "Epoch 195/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0424 - accuracy: 0.7331\n",
      "Epoch 196/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0427 - accuracy: 0.7506\n",
      "Epoch 197/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0428 - accuracy: 0.7398\n",
      "Epoch 198/500\n",
      "1199/1199 [==============================] - 0s 26us/step - loss: 0.0421 - accuracy: 0.7498\n",
      "Epoch 199/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0413 - accuracy: 0.7581\n",
      "Epoch 200/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0418 - accuracy: 0.7498\n",
      "Epoch 201/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0413 - accuracy: 0.7681\n",
      "Epoch 202/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0419 - accuracy: 0.7389\n",
      "Epoch 203/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0422 - accuracy: 0.7548\n",
      "Epoch 204/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0414 - accuracy: 0.7448\n",
      "Epoch 205/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0424 - accuracy: 0.7531\n",
      "Epoch 206/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0417 - accuracy: 0.7573\n",
      "Epoch 207/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0407 - accuracy: 0.7665\n",
      "Epoch 208/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0425 - accuracy: 0.7465\n",
      "Epoch 209/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0416 - accuracy: 0.7523\n",
      "Epoch 210/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0414 - accuracy: 0.7590\n",
      "Epoch 211/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0413 - accuracy: 0.7573\n",
      "Epoch 212/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0412 - accuracy: 0.7631\n",
      "Epoch 213/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0418 - accuracy: 0.7640\n",
      "Epoch 214/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0408 - accuracy: 0.7548\n",
      "Epoch 215/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0408 - accuracy: 0.7631\n",
      "Epoch 216/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0415 - accuracy: 0.7531\n",
      "Epoch 217/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0406 - accuracy: 0.7740\n",
      "Epoch 218/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0424 - accuracy: 0.7515\n",
      "Epoch 219/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0405 - accuracy: 0.7640\n",
      "Epoch 220/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0415 - accuracy: 0.7431\n",
      "Epoch 221/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0409 - accuracy: 0.7631\n",
      "Epoch 222/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0408 - accuracy: 0.7556\n",
      "Epoch 223/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0413 - accuracy: 0.7540\n",
      "Epoch 224/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0401 - accuracy: 0.7640\n",
      "Epoch 225/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0402 - accuracy: 0.7715\n",
      "Epoch 226/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0415 - accuracy: 0.7523\n",
      "Epoch 227/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0410 - accuracy: 0.7565\n",
      "Epoch 228/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0404 - accuracy: 0.7665\n",
      "Epoch 229/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0409 - accuracy: 0.7573\n",
      "Epoch 230/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0400 - accuracy: 0.7648\n",
      "Epoch 231/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0408 - accuracy: 0.7606\n",
      "Epoch 232/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0401 - accuracy: 0.7631\n",
      "Epoch 233/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0399 - accuracy: 0.7748\n",
      "Epoch 234/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0405 - accuracy: 0.7623\n",
      "Epoch 235/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0398 - accuracy: 0.7656\n",
      "Epoch 236/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0396 - accuracy: 0.7723\n",
      "Epoch 237/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0410 - accuracy: 0.7540\n",
      "Epoch 238/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0393 - accuracy: 0.7781\n",
      "Epoch 239/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0398 - accuracy: 0.7706\n",
      "Epoch 240/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0398 - accuracy: 0.7748\n",
      "Epoch 241/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0395 - accuracy: 0.7690\n",
      "Epoch 242/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0399 - accuracy: 0.7665\n",
      "Epoch 243/500\n",
      "1199/1199 [==============================] - 0s 26us/step - loss: 0.0403 - accuracy: 0.7556\n",
      "Epoch 244/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0395 - accuracy: 0.7756\n",
      "Epoch 245/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0388 - accuracy: 0.7807\n",
      "Epoch 246/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0395 - accuracy: 0.7681\n",
      "Epoch 247/500\n",
      "1199/1199 [==============================] - 0s 26us/step - loss: 0.0398 - accuracy: 0.7606\n",
      "Epoch 248/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0393 - accuracy: 0.7832\n",
      "Epoch 249/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0393 - accuracy: 0.7656\n",
      "Epoch 250/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0381 - accuracy: 0.7907\n",
      "Epoch 251/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0398 - accuracy: 0.7798\n",
      "Epoch 252/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0382 - accuracy: 0.7832\n",
      "Epoch 253/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0394 - accuracy: 0.7731\n",
      "Epoch 254/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0388 - accuracy: 0.7748\n",
      "Epoch 255/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0388 - accuracy: 0.7790\n",
      "Epoch 256/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0390 - accuracy: 0.7723\n",
      "Epoch 257/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0382 - accuracy: 0.7832\n",
      "Epoch 258/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0382 - accuracy: 0.7765\n",
      "Epoch 259/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0392 - accuracy: 0.7690\n",
      "Epoch 260/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0385 - accuracy: 0.7748\n",
      "Epoch 261/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0394 - accuracy: 0.7715\n",
      "Epoch 262/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0388 - accuracy: 0.7723\n",
      "Epoch 263/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0380 - accuracy: 0.7790\n",
      "Epoch 264/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0382 - accuracy: 0.7823\n",
      "Epoch 265/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0389 - accuracy: 0.7798\n",
      "Epoch 266/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0376 - accuracy: 0.7815\n",
      "Epoch 267/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0380 - accuracy: 0.7781\n",
      "Epoch 268/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0375 - accuracy: 0.7898\n",
      "Epoch 269/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0389 - accuracy: 0.7798\n",
      "Epoch 270/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0388 - accuracy: 0.7848\n",
      "Epoch 271/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0381 - accuracy: 0.7932\n",
      "Epoch 272/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0374 - accuracy: 0.7890\n",
      "Epoch 273/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0367 - accuracy: 0.7957\n",
      "Epoch 274/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0378 - accuracy: 0.7907\n",
      "Epoch 275/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0387 - accuracy: 0.7857\n",
      "Epoch 276/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0383 - accuracy: 0.7756\n",
      "Epoch 277/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0380 - accuracy: 0.7756\n",
      "Epoch 278/500\n",
      "1199/1199 [==============================] - 0s 28us/step - loss: 0.0374 - accuracy: 0.7873\n",
      "Epoch 279/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0381 - accuracy: 0.7848\n",
      "Epoch 280/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0375 - accuracy: 0.7765\n",
      "Epoch 281/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0385 - accuracy: 0.7756\n",
      "Epoch 282/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0373 - accuracy: 0.7882\n",
      "Epoch 283/500\n",
      "1199/1199 [==============================] - 0s 45us/step - loss: 0.0372 - accuracy: 0.7923\n",
      "Epoch 284/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0372 - accuracy: 0.7957\n",
      "Epoch 285/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0371 - accuracy: 0.7857\n",
      "Epoch 286/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0379 - accuracy: 0.7748\n",
      "Epoch 287/500\n",
      "1199/1199 [==============================] - 0s 26us/step - loss: 0.0368 - accuracy: 0.7882\n",
      "Epoch 288/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0355 - accuracy: 0.7990\n",
      "Epoch 289/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0372 - accuracy: 0.7873\n",
      "Epoch 290/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0377 - accuracy: 0.7815\n",
      "Epoch 291/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0379 - accuracy: 0.7840\n",
      "Epoch 292/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0365 - accuracy: 0.7948\n",
      "Epoch 293/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0372 - accuracy: 0.7932\n",
      "Epoch 294/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0382 - accuracy: 0.7807\n",
      "Epoch 295/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0367 - accuracy: 0.7957\n",
      "Epoch 296/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0369 - accuracy: 0.7890\n",
      "Epoch 297/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0359 - accuracy: 0.7957\n",
      "Epoch 298/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0368 - accuracy: 0.7923\n",
      "Epoch 299/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0366 - accuracy: 0.7982\n",
      "Epoch 300/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0363 - accuracy: 0.7998\n",
      "Epoch 301/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0362 - accuracy: 0.7915\n",
      "Epoch 302/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0364 - accuracy: 0.7932\n",
      "Epoch 303/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0360 - accuracy: 0.8057\n",
      "Epoch 304/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0357 - accuracy: 0.7948\n",
      "Epoch 305/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0352 - accuracy: 0.8015\n",
      "Epoch 306/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0363 - accuracy: 0.8015\n",
      "Epoch 307/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0369 - accuracy: 0.7873\n",
      "Epoch 308/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0369 - accuracy: 0.7898\n",
      "Epoch 309/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0368 - accuracy: 0.7807\n",
      "Epoch 310/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0362 - accuracy: 0.7907\n",
      "Epoch 311/500\n",
      "1199/1199 [==============================] - 0s 26us/step - loss: 0.0354 - accuracy: 0.8032\n",
      "Epoch 312/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0359 - accuracy: 0.8082\n",
      "Epoch 313/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0360 - accuracy: 0.7915\n",
      "Epoch 314/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0361 - accuracy: 0.8023\n",
      "Epoch 315/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0364 - accuracy: 0.7865\n",
      "Epoch 316/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0368 - accuracy: 0.7840\n",
      "Epoch 317/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0356 - accuracy: 0.7965\n",
      "Epoch 318/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0353 - accuracy: 0.8048\n",
      "Epoch 319/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0342 - accuracy: 0.8098\n",
      "Epoch 320/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0360 - accuracy: 0.7915\n",
      "Epoch 321/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0358 - accuracy: 0.7965\n",
      "Epoch 322/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0366 - accuracy: 0.7948\n",
      "Epoch 323/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0356 - accuracy: 0.8015\n",
      "Epoch 324/500\n",
      "1199/1199 [==============================] - 0s 29us/step - loss: 0.0356 - accuracy: 0.7990\n",
      "Epoch 325/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0358 - accuracy: 0.7932\n",
      "Epoch 326/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0345 - accuracy: 0.8073\n",
      "Epoch 327/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0346 - accuracy: 0.8107\n",
      "Epoch 328/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0352 - accuracy: 0.8048\n",
      "Epoch 329/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0355 - accuracy: 0.8065\n",
      "Epoch 330/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0348 - accuracy: 0.8048\n",
      "Epoch 331/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0347 - accuracy: 0.8040\n",
      "Epoch 332/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0342 - accuracy: 0.8057\n",
      "Epoch 333/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0344 - accuracy: 0.8007\n",
      "Epoch 334/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0358 - accuracy: 0.8023\n",
      "Epoch 335/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0354 - accuracy: 0.8032\n",
      "Epoch 336/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0334 - accuracy: 0.8274\n",
      "Epoch 337/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0340 - accuracy: 0.8090\n",
      "Epoch 338/500\n",
      "1199/1199 [==============================] - 0s 28us/step - loss: 0.0343 - accuracy: 0.8073\n",
      "Epoch 339/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0351 - accuracy: 0.8032\n",
      "Epoch 340/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0336 - accuracy: 0.8098\n",
      "Epoch 341/500\n",
      "1199/1199 [==============================] - 0s 28us/step - loss: 0.0346 - accuracy: 0.8040\n",
      "Epoch 342/500\n",
      "1199/1199 [==============================] - 0s 26us/step - loss: 0.0343 - accuracy: 0.8115\n",
      "Epoch 343/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0347 - accuracy: 0.8073\n",
      "Epoch 344/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0346 - accuracy: 0.8032\n",
      "Epoch 345/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0350 - accuracy: 0.8048\n",
      "Epoch 346/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0341 - accuracy: 0.8090\n",
      "Epoch 347/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0355 - accuracy: 0.7998\n",
      "Epoch 348/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0341 - accuracy: 0.8107\n",
      "Epoch 349/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0350 - accuracy: 0.7973\n",
      "Epoch 350/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0332 - accuracy: 0.8207\n",
      "Epoch 351/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0339 - accuracy: 0.8065\n",
      "Epoch 352/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0352 - accuracy: 0.7957\n",
      "Epoch 353/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0346 - accuracy: 0.8082\n",
      "Epoch 354/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0339 - accuracy: 0.8115\n",
      "Epoch 355/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0340 - accuracy: 0.8115\n",
      "Epoch 356/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0337 - accuracy: 0.8140\n",
      "Epoch 357/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0342 - accuracy: 0.8032\n",
      "Epoch 358/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0347 - accuracy: 0.8057\n",
      "Epoch 359/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0334 - accuracy: 0.8190\n",
      "Epoch 360/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0341 - accuracy: 0.8098\n",
      "Epoch 361/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0343 - accuracy: 0.8090\n",
      "Epoch 362/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0344 - accuracy: 0.8090\n",
      "Epoch 363/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0335 - accuracy: 0.8057\n",
      "Epoch 364/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0343 - accuracy: 0.8007\n",
      "Epoch 365/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0337 - accuracy: 0.8073\n",
      "Epoch 366/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0333 - accuracy: 0.8198\n",
      "Epoch 367/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0341 - accuracy: 0.8123\n",
      "Epoch 368/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0342 - accuracy: 0.8073\n",
      "Epoch 369/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0339 - accuracy: 0.8198\n",
      "Epoch 370/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0340 - accuracy: 0.8165\n",
      "Epoch 371/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0335 - accuracy: 0.8132\n",
      "Epoch 372/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0333 - accuracy: 0.8182\n",
      "Epoch 373/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0336 - accuracy: 0.8140\n",
      "Epoch 374/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0336 - accuracy: 0.8082\n",
      "Epoch 375/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0344 - accuracy: 0.8098\n",
      "Epoch 376/500\n",
      "1199/1199 [==============================] - 0s 16us/step - loss: 0.0335 - accuracy: 0.8123\n",
      "Epoch 377/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0326 - accuracy: 0.8198\n",
      "Epoch 378/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0329 - accuracy: 0.8140\n",
      "Epoch 379/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0322 - accuracy: 0.8315\n",
      "Epoch 380/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0319 - accuracy: 0.8232\n",
      "Epoch 381/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0336 - accuracy: 0.8123\n",
      "Epoch 382/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0327 - accuracy: 0.8240\n",
      "Epoch 383/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0331 - accuracy: 0.8198\n",
      "Epoch 384/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0328 - accuracy: 0.8182\n",
      "Epoch 385/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0340 - accuracy: 0.8107\n",
      "Epoch 386/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0338 - accuracy: 0.8140\n",
      "Epoch 387/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0329 - accuracy: 0.8198\n",
      "Epoch 388/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0318 - accuracy: 0.8290\n",
      "Epoch 389/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0326 - accuracy: 0.8274\n",
      "Epoch 390/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0323 - accuracy: 0.8282\n",
      "Epoch 391/500\n",
      "1199/1199 [==============================] - 0s 27us/step - loss: 0.0327 - accuracy: 0.8123\n",
      "Epoch 392/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0319 - accuracy: 0.8324\n",
      "Epoch 393/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0328 - accuracy: 0.8207\n",
      "Epoch 394/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0327 - accuracy: 0.8207\n",
      "Epoch 395/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0319 - accuracy: 0.8224\n",
      "Epoch 396/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0313 - accuracy: 0.8299\n",
      "Epoch 397/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0312 - accuracy: 0.8282\n",
      "Epoch 398/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0319 - accuracy: 0.8274\n",
      "Epoch 399/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0330 - accuracy: 0.8123\n",
      "Epoch 400/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0321 - accuracy: 0.8265\n",
      "Epoch 401/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0309 - accuracy: 0.8299\n",
      "Epoch 402/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0327 - accuracy: 0.8215\n",
      "Epoch 403/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0310 - accuracy: 0.8374\n",
      "Epoch 404/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0316 - accuracy: 0.8249\n",
      "Epoch 405/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0311 - accuracy: 0.8374\n",
      "Epoch 406/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0323 - accuracy: 0.8207\n",
      "Epoch 407/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0312 - accuracy: 0.8324\n",
      "Epoch 408/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0329 - accuracy: 0.8198\n",
      "Epoch 409/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0310 - accuracy: 0.8240\n",
      "Epoch 410/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0311 - accuracy: 0.8299\n",
      "Epoch 411/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0311 - accuracy: 0.8232\n",
      "Epoch 412/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0324 - accuracy: 0.8257\n",
      "Epoch 413/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0316 - accuracy: 0.8265\n",
      "Epoch 414/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0314 - accuracy: 0.8349\n",
      "Epoch 415/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0325 - accuracy: 0.8090\n",
      "Epoch 416/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0305 - accuracy: 0.8332\n",
      "Epoch 417/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0313 - accuracy: 0.8324\n",
      "Epoch 418/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0313 - accuracy: 0.8282\n",
      "Epoch 419/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0309 - accuracy: 0.8324\n",
      "Epoch 420/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0312 - accuracy: 0.8315\n",
      "Epoch 421/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0311 - accuracy: 0.8240\n",
      "Epoch 422/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0326 - accuracy: 0.8182\n",
      "Epoch 423/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0313 - accuracy: 0.8257\n",
      "Epoch 424/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0301 - accuracy: 0.8365\n",
      "Epoch 425/500\n",
      "1199/1199 [==============================] - 0s 26us/step - loss: 0.0317 - accuracy: 0.8198\n",
      "Epoch 426/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0303 - accuracy: 0.8307\n",
      "Epoch 427/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0316 - accuracy: 0.8299\n",
      "Epoch 428/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0310 - accuracy: 0.8349\n",
      "Epoch 429/500\n",
      "1199/1199 [==============================] - 0s 27us/step - loss: 0.0301 - accuracy: 0.8407\n",
      "Epoch 430/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0315 - accuracy: 0.8290\n",
      "Epoch 431/500\n",
      "1199/1199 [==============================] - 0s 27us/step - loss: 0.0313 - accuracy: 0.8324\n",
      "Epoch 432/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0301 - accuracy: 0.8365\n",
      "Epoch 433/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0309 - accuracy: 0.8240\n",
      "Epoch 434/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0315 - accuracy: 0.8232\n",
      "Epoch 435/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0304 - accuracy: 0.8349\n",
      "Epoch 436/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0315 - accuracy: 0.8357\n",
      "Epoch 437/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0305 - accuracy: 0.8349\n",
      "Epoch 438/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0308 - accuracy: 0.8374\n",
      "Epoch 439/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0299 - accuracy: 0.8390\n",
      "Epoch 440/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0311 - accuracy: 0.8357\n",
      "Epoch 441/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0301 - accuracy: 0.8390\n",
      "Epoch 442/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0304 - accuracy: 0.8340\n",
      "Epoch 443/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0303 - accuracy: 0.8382\n",
      "Epoch 444/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0301 - accuracy: 0.8357\n",
      "Epoch 445/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0304 - accuracy: 0.8424\n",
      "Epoch 446/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0306 - accuracy: 0.8349\n",
      "Epoch 447/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0302 - accuracy: 0.8357\n",
      "Epoch 448/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0306 - accuracy: 0.8332\n",
      "Epoch 449/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0305 - accuracy: 0.8432\n",
      "Epoch 450/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0301 - accuracy: 0.8340\n",
      "Epoch 451/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0293 - accuracy: 0.8390\n",
      "Epoch 452/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0306 - accuracy: 0.8299\n",
      "Epoch 453/500\n",
      "1199/1199 [==============================] - 0s 17us/step - loss: 0.0296 - accuracy: 0.8357\n",
      "Epoch 454/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0301 - accuracy: 0.8349\n",
      "Epoch 455/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0302 - accuracy: 0.8340\n",
      "Epoch 456/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0296 - accuracy: 0.8449\n",
      "Epoch 457/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0304 - accuracy: 0.8315\n",
      "Epoch 458/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0303 - accuracy: 0.8374\n",
      "Epoch 459/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0297 - accuracy: 0.8390\n",
      "Epoch 460/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0293 - accuracy: 0.8407\n",
      "Epoch 461/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0301 - accuracy: 0.8365\n",
      "Epoch 462/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0299 - accuracy: 0.8365\n",
      "Epoch 463/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0301 - accuracy: 0.8357\n",
      "Epoch 464/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0305 - accuracy: 0.8357\n",
      "Epoch 465/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0292 - accuracy: 0.8407\n",
      "Epoch 466/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0298 - accuracy: 0.8357\n",
      "Epoch 467/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0302 - accuracy: 0.8324\n",
      "Epoch 468/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0293 - accuracy: 0.8365\n",
      "Epoch 469/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0304 - accuracy: 0.8282\n",
      "Epoch 470/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0295 - accuracy: 0.8382\n",
      "Epoch 471/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0295 - accuracy: 0.8482\n",
      "Epoch 472/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0287 - accuracy: 0.8515\n",
      "Epoch 473/500\n",
      "1199/1199 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.83 - 0s 21us/step - loss: 0.0288 - accuracy: 0.8499\n",
      "Epoch 474/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0298 - accuracy: 0.8332\n",
      "Epoch 475/500\n",
      "1199/1199 [==============================] - 0s 24us/step - loss: 0.0283 - accuracy: 0.8515\n",
      "Epoch 476/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0289 - accuracy: 0.8449\n",
      "Epoch 477/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0288 - accuracy: 0.8490\n",
      "Epoch 478/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0304 - accuracy: 0.8290\n",
      "Epoch 479/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0289 - accuracy: 0.8457\n",
      "Epoch 480/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0292 - accuracy: 0.8390\n",
      "Epoch 481/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0289 - accuracy: 0.8382\n",
      "Epoch 482/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0301 - accuracy: 0.8357\n",
      "Epoch 483/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0302 - accuracy: 0.8382\n",
      "Epoch 484/500\n",
      "1199/1199 [==============================] - 0s 18us/step - loss: 0.0280 - accuracy: 0.8565\n",
      "Epoch 485/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0287 - accuracy: 0.8532\n",
      "Epoch 486/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0290 - accuracy: 0.8390\n",
      "Epoch 487/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0288 - accuracy: 0.8482\n",
      "Epoch 488/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0288 - accuracy: 0.8457\n",
      "Epoch 489/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0284 - accuracy: 0.8482\n",
      "Epoch 490/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0275 - accuracy: 0.8624\n",
      "Epoch 491/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0282 - accuracy: 0.8565\n",
      "Epoch 492/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0288 - accuracy: 0.8449\n",
      "Epoch 493/500\n",
      "1199/1199 [==============================] - 0s 22us/step - loss: 0.0293 - accuracy: 0.8382\n",
      "Epoch 494/500\n",
      "1199/1199 [==============================] - 0s 25us/step - loss: 0.0281 - accuracy: 0.8499\n",
      "Epoch 495/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0299 - accuracy: 0.8357\n",
      "Epoch 496/500\n",
      "1199/1199 [==============================] - 0s 23us/step - loss: 0.0288 - accuracy: 0.8399\n",
      "Epoch 497/500\n",
      "1199/1199 [==============================] - 0s 21us/step - loss: 0.0281 - accuracy: 0.8474\n",
      "Epoch 498/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0286 - accuracy: 0.8474\n",
      "Epoch 499/500\n",
      "1199/1199 [==============================] - 0s 20us/step - loss: 0.0284 - accuracy: 0.8474\n",
      "Epoch 500/500\n",
      "1199/1199 [==============================] - 0s 19us/step - loss: 0.0286 - accuracy: 0.8474\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X_train_scaled, y_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.wrappers.scikit_learn.KerasClassifier object at 0x000001EBB59EDA90>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['NN_grid_best_estimator.pkl']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the Grid Estimator from sklearn.externals import joblib\n",
    "print(grid.best_estimator_)\n",
    "joblib.dump(grid.best_estimator_, 'NN_grid_best_estimator.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 500, 'dropout_rate': 0.2, 'epochs': 500}\n",
      "0.6263552964280504\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = grid.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.72      0.70      0.71       169\n",
      "           6       0.57      0.74      0.64       149\n",
      "           7       0.69      0.48      0.57        60\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.64       400\n",
      "   macro avg       0.33      0.32      0.32       400\n",
      "weighted avg       0.62      0.64      0.63       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Model using the Grid Estimators Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 500 500\n"
     ]
    }
   ],
   "source": [
    "dropout_rate = grid.best_params_['dropout_rate']\n",
    "epochs = grid.best_params_['epochs']\n",
    "batch_size = grid.best_params_['batch_size']\n",
    "\n",
    "print(dropout_rate, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_NN_model = create_model(dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1199 samples, validate on 400 samples\n",
      "Epoch 1/500\n",
      " - 1s - loss: 0.1000 - accuracy: 0.1251 - val_loss: 0.0967 - val_accuracy: 0.2625\n",
      "Epoch 2/500\n",
      " - 0s - loss: 0.0952 - accuracy: 0.3219 - val_loss: 0.0918 - val_accuracy: 0.3700\n",
      "Epoch 3/500\n",
      " - 0s - loss: 0.0902 - accuracy: 0.3703 - val_loss: 0.0870 - val_accuracy: 0.4050\n",
      "Epoch 4/500\n",
      " - 0s - loss: 0.0856 - accuracy: 0.4153 - val_loss: 0.0825 - val_accuracy: 0.4575\n",
      "Epoch 5/500\n",
      " - 0s - loss: 0.0813 - accuracy: 0.4696 - val_loss: 0.0783 - val_accuracy: 0.5375\n",
      "Epoch 6/500\n",
      " - 0s - loss: 0.0772 - accuracy: 0.5279 - val_loss: 0.0746 - val_accuracy: 0.5600\n",
      "Epoch 7/500\n",
      " - 0s - loss: 0.0734 - accuracy: 0.5505 - val_loss: 0.0714 - val_accuracy: 0.5625\n",
      "Epoch 8/500\n",
      " - 0s - loss: 0.0698 - accuracy: 0.5680 - val_loss: 0.0689 - val_accuracy: 0.5425\n",
      "Epoch 9/500\n",
      " - 0s - loss: 0.0677 - accuracy: 0.5563 - val_loss: 0.0669 - val_accuracy: 0.5450\n",
      "Epoch 10/500\n",
      " - 0s - loss: 0.0655 - accuracy: 0.5630 - val_loss: 0.0650 - val_accuracy: 0.5675\n",
      "Epoch 11/500\n",
      " - 0s - loss: 0.0635 - accuracy: 0.5730 - val_loss: 0.0633 - val_accuracy: 0.5725\n",
      "Epoch 12/500\n",
      " - 0s - loss: 0.0625 - accuracy: 0.5830 - val_loss: 0.0621 - val_accuracy: 0.5850\n",
      "Epoch 13/500\n",
      " - 0s - loss: 0.0617 - accuracy: 0.5855 - val_loss: 0.0613 - val_accuracy: 0.6125\n",
      "Epoch 14/500\n",
      " - 0s - loss: 0.0610 - accuracy: 0.5947 - val_loss: 0.0608 - val_accuracy: 0.6200\n",
      "Epoch 15/500\n",
      " - 0s - loss: 0.0608 - accuracy: 0.5830 - val_loss: 0.0606 - val_accuracy: 0.6200\n",
      "Epoch 16/500\n",
      " - 0s - loss: 0.0603 - accuracy: 0.5988 - val_loss: 0.0604 - val_accuracy: 0.6250\n",
      "Epoch 17/500\n",
      " - 0s - loss: 0.0592 - accuracy: 0.5963 - val_loss: 0.0604 - val_accuracy: 0.6225\n",
      "Epoch 18/500\n",
      " - 0s - loss: 0.0597 - accuracy: 0.6013 - val_loss: 0.0605 - val_accuracy: 0.6225\n",
      "Epoch 19/500\n",
      " - 0s - loss: 0.0596 - accuracy: 0.5997 - val_loss: 0.0604 - val_accuracy: 0.6200\n",
      "Epoch 20/500\n",
      " - 0s - loss: 0.0586 - accuracy: 0.6147 - val_loss: 0.0603 - val_accuracy: 0.6275\n",
      "Epoch 21/500\n",
      " - 0s - loss: 0.0588 - accuracy: 0.6072 - val_loss: 0.0600 - val_accuracy: 0.6175\n",
      "Epoch 22/500\n",
      " - 0s - loss: 0.0583 - accuracy: 0.6222 - val_loss: 0.0597 - val_accuracy: 0.6125\n",
      "Epoch 23/500\n",
      " - 0s - loss: 0.0575 - accuracy: 0.6205 - val_loss: 0.0596 - val_accuracy: 0.6175\n",
      "Epoch 24/500\n",
      " - 0s - loss: 0.0577 - accuracy: 0.6239 - val_loss: 0.0596 - val_accuracy: 0.6200\n",
      "Epoch 25/500\n",
      " - 0s - loss: 0.0578 - accuracy: 0.6239 - val_loss: 0.0596 - val_accuracy: 0.6200\n",
      "Epoch 26/500\n",
      " - 0s - loss: 0.0575 - accuracy: 0.6197 - val_loss: 0.0597 - val_accuracy: 0.6125\n",
      "Epoch 27/500\n",
      " - 0s - loss: 0.0572 - accuracy: 0.6322 - val_loss: 0.0597 - val_accuracy: 0.6150\n",
      "Epoch 28/500\n",
      " - 0s - loss: 0.0571 - accuracy: 0.6314 - val_loss: 0.0596 - val_accuracy: 0.6225\n",
      "Epoch 29/500\n",
      " - 0s - loss: 0.0569 - accuracy: 0.6322 - val_loss: 0.0596 - val_accuracy: 0.6275\n",
      "Epoch 30/500\n",
      " - 0s - loss: 0.0568 - accuracy: 0.6205 - val_loss: 0.0594 - val_accuracy: 0.6225\n",
      "Epoch 31/500\n",
      " - 0s - loss: 0.0565 - accuracy: 0.6289 - val_loss: 0.0592 - val_accuracy: 0.6275\n",
      "Epoch 32/500\n",
      " - 0s - loss: 0.0572 - accuracy: 0.6188 - val_loss: 0.0592 - val_accuracy: 0.6225\n",
      "Epoch 33/500\n",
      " - 0s - loss: 0.0562 - accuracy: 0.6347 - val_loss: 0.0592 - val_accuracy: 0.6225\n",
      "Epoch 34/500\n",
      " - 0s - loss: 0.0559 - accuracy: 0.6380 - val_loss: 0.0592 - val_accuracy: 0.6200\n",
      "Epoch 35/500\n",
      " - 0s - loss: 0.0563 - accuracy: 0.6272 - val_loss: 0.0592 - val_accuracy: 0.6225\n",
      "Epoch 36/500\n",
      " - 0s - loss: 0.0554 - accuracy: 0.6430 - val_loss: 0.0592 - val_accuracy: 0.6200\n",
      "Epoch 37/500\n",
      " - 0s - loss: 0.0564 - accuracy: 0.6372 - val_loss: 0.0591 - val_accuracy: 0.6200\n",
      "Epoch 38/500\n",
      " - 0s - loss: 0.0560 - accuracy: 0.6439 - val_loss: 0.0590 - val_accuracy: 0.6225\n",
      "Epoch 39/500\n",
      " - 0s - loss: 0.0554 - accuracy: 0.6380 - val_loss: 0.0590 - val_accuracy: 0.6275\n",
      "Epoch 40/500\n",
      " - 0s - loss: 0.0558 - accuracy: 0.6389 - val_loss: 0.0592 - val_accuracy: 0.6275\n",
      "Epoch 41/500\n",
      " - 0s - loss: 0.0554 - accuracy: 0.6464 - val_loss: 0.0591 - val_accuracy: 0.6225\n",
      "Epoch 42/500\n",
      " - 0s - loss: 0.0555 - accuracy: 0.6289 - val_loss: 0.0591 - val_accuracy: 0.6175\n",
      "Epoch 43/500\n",
      " - 0s - loss: 0.0554 - accuracy: 0.6380 - val_loss: 0.0590 - val_accuracy: 0.6150\n",
      "Epoch 44/500\n",
      " - 0s - loss: 0.0553 - accuracy: 0.6322 - val_loss: 0.0591 - val_accuracy: 0.6150\n",
      "Epoch 45/500\n",
      " - 0s - loss: 0.0549 - accuracy: 0.6430 - val_loss: 0.0592 - val_accuracy: 0.6175\n",
      "Epoch 46/500\n",
      " - 0s - loss: 0.0557 - accuracy: 0.6405 - val_loss: 0.0592 - val_accuracy: 0.6175\n",
      "Epoch 47/500\n",
      " - 0s - loss: 0.0542 - accuracy: 0.6572 - val_loss: 0.0591 - val_accuracy: 0.6125\n",
      "Epoch 48/500\n",
      " - 0s - loss: 0.0549 - accuracy: 0.6464 - val_loss: 0.0590 - val_accuracy: 0.6050\n",
      "Epoch 49/500\n",
      " - 0s - loss: 0.0547 - accuracy: 0.6555 - val_loss: 0.0588 - val_accuracy: 0.6075\n",
      "Epoch 50/500\n",
      " - 0s - loss: 0.0549 - accuracy: 0.6480 - val_loss: 0.0589 - val_accuracy: 0.6100\n",
      "Epoch 51/500\n",
      " - 0s - loss: 0.0547 - accuracy: 0.6480 - val_loss: 0.0590 - val_accuracy: 0.6125\n",
      "Epoch 52/500\n",
      " - 0s - loss: 0.0546 - accuracy: 0.6464 - val_loss: 0.0591 - val_accuracy: 0.6175\n",
      "Epoch 53/500\n",
      " - 0s - loss: 0.0545 - accuracy: 0.6497 - val_loss: 0.0589 - val_accuracy: 0.6150\n",
      "Epoch 54/500\n",
      " - 0s - loss: 0.0542 - accuracy: 0.6597 - val_loss: 0.0590 - val_accuracy: 0.6175\n",
      "Epoch 55/500\n",
      " - 0s - loss: 0.0541 - accuracy: 0.6489 - val_loss: 0.0588 - val_accuracy: 0.6225\n",
      "Epoch 56/500\n",
      " - 0s - loss: 0.0536 - accuracy: 0.6639 - val_loss: 0.0587 - val_accuracy: 0.6200\n",
      "Epoch 57/500\n",
      " - 0s - loss: 0.0540 - accuracy: 0.6472 - val_loss: 0.0587 - val_accuracy: 0.6125\n",
      "Epoch 58/500\n",
      " - 0s - loss: 0.0543 - accuracy: 0.6530 - val_loss: 0.0586 - val_accuracy: 0.6200\n",
      "Epoch 59/500\n",
      " - 0s - loss: 0.0539 - accuracy: 0.6572 - val_loss: 0.0587 - val_accuracy: 0.6175\n",
      "Epoch 60/500\n",
      " - 0s - loss: 0.0537 - accuracy: 0.6589 - val_loss: 0.0587 - val_accuracy: 0.6125\n",
      "Epoch 61/500\n",
      " - 0s - loss: 0.0525 - accuracy: 0.6664 - val_loss: 0.0588 - val_accuracy: 0.6125\n",
      "Epoch 62/500\n",
      " - 0s - loss: 0.0528 - accuracy: 0.6555 - val_loss: 0.0588 - val_accuracy: 0.6150\n",
      "Epoch 63/500\n",
      " - 0s - loss: 0.0528 - accuracy: 0.6672 - val_loss: 0.0588 - val_accuracy: 0.6150\n",
      "Epoch 64/500\n",
      " - 0s - loss: 0.0525 - accuracy: 0.6639 - val_loss: 0.0588 - val_accuracy: 0.6100\n",
      "Epoch 65/500\n",
      " - 0s - loss: 0.0525 - accuracy: 0.6664 - val_loss: 0.0587 - val_accuracy: 0.6150\n",
      "Epoch 66/500\n",
      " - 0s - loss: 0.0534 - accuracy: 0.6480 - val_loss: 0.0586 - val_accuracy: 0.6175\n",
      "Epoch 67/500\n",
      " - 0s - loss: 0.0525 - accuracy: 0.6697 - val_loss: 0.0584 - val_accuracy: 0.6150\n",
      "Epoch 68/500\n",
      " - 0s - loss: 0.0526 - accuracy: 0.6647 - val_loss: 0.0582 - val_accuracy: 0.6125\n",
      "Epoch 69/500\n",
      " - 0s - loss: 0.0525 - accuracy: 0.6606 - val_loss: 0.0581 - val_accuracy: 0.6075\n",
      "Epoch 70/500\n",
      " - 0s - loss: 0.0522 - accuracy: 0.6597 - val_loss: 0.0582 - val_accuracy: 0.6200\n",
      "Epoch 71/500\n",
      " - 0s - loss: 0.0511 - accuracy: 0.6697 - val_loss: 0.0584 - val_accuracy: 0.6300\n",
      "Epoch 72/500\n",
      " - 0s - loss: 0.0524 - accuracy: 0.6530 - val_loss: 0.0583 - val_accuracy: 0.6250\n",
      "Epoch 73/500\n",
      " - 0s - loss: 0.0522 - accuracy: 0.6647 - val_loss: 0.0581 - val_accuracy: 0.6225\n",
      "Epoch 74/500\n",
      " - 0s - loss: 0.0517 - accuracy: 0.6681 - val_loss: 0.0580 - val_accuracy: 0.6050\n",
      "Epoch 75/500\n",
      " - 0s - loss: 0.0522 - accuracy: 0.6664 - val_loss: 0.0580 - val_accuracy: 0.6100\n",
      "Epoch 76/500\n",
      " - 0s - loss: 0.0521 - accuracy: 0.6522 - val_loss: 0.0583 - val_accuracy: 0.6150\n",
      "Epoch 77/500\n",
      " - 0s - loss: 0.0519 - accuracy: 0.6564 - val_loss: 0.0587 - val_accuracy: 0.6250\n",
      "Epoch 78/500\n",
      " - 0s - loss: 0.0518 - accuracy: 0.6597 - val_loss: 0.0588 - val_accuracy: 0.6175\n",
      "Epoch 79/500\n",
      " - 0s - loss: 0.0513 - accuracy: 0.6739 - val_loss: 0.0586 - val_accuracy: 0.6200\n",
      "Epoch 80/500\n",
      " - 0s - loss: 0.0510 - accuracy: 0.6764 - val_loss: 0.0585 - val_accuracy: 0.6175\n",
      "Epoch 81/500\n",
      " - 0s - loss: 0.0517 - accuracy: 0.6656 - val_loss: 0.0583 - val_accuracy: 0.6250\n",
      "Epoch 82/500\n",
      " - 0s - loss: 0.0503 - accuracy: 0.6856 - val_loss: 0.0584 - val_accuracy: 0.6250\n",
      "Epoch 83/500\n",
      " - 0s - loss: 0.0512 - accuracy: 0.6731 - val_loss: 0.0586 - val_accuracy: 0.6200\n",
      "Epoch 84/500\n",
      " - 0s - loss: 0.0509 - accuracy: 0.6756 - val_loss: 0.0588 - val_accuracy: 0.6225\n",
      "Epoch 85/500\n",
      " - 0s - loss: 0.0514 - accuracy: 0.6689 - val_loss: 0.0588 - val_accuracy: 0.6125\n",
      "Epoch 86/500\n",
      " - 0s - loss: 0.0508 - accuracy: 0.6772 - val_loss: 0.0588 - val_accuracy: 0.6175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/500\n",
      " - 0s - loss: 0.0504 - accuracy: 0.6864 - val_loss: 0.0588 - val_accuracy: 0.6150\n",
      "Epoch 88/500\n",
      " - 0s - loss: 0.0507 - accuracy: 0.6739 - val_loss: 0.0586 - val_accuracy: 0.6200\n",
      "Epoch 89/500\n",
      " - 0s - loss: 0.0507 - accuracy: 0.6756 - val_loss: 0.0585 - val_accuracy: 0.6200\n",
      "Epoch 90/500\n",
      " - 0s - loss: 0.0506 - accuracy: 0.6722 - val_loss: 0.0583 - val_accuracy: 0.6375\n",
      "Epoch 91/500\n",
      " - 0s - loss: 0.0503 - accuracy: 0.6839 - val_loss: 0.0583 - val_accuracy: 0.6250\n",
      "Epoch 92/500\n",
      " - 0s - loss: 0.0490 - accuracy: 0.6939 - val_loss: 0.0582 - val_accuracy: 0.6250\n",
      "Epoch 93/500\n",
      " - 0s - loss: 0.0491 - accuracy: 0.6831 - val_loss: 0.0582 - val_accuracy: 0.6325\n",
      "Epoch 94/500\n",
      " - 0s - loss: 0.0501 - accuracy: 0.6839 - val_loss: 0.0584 - val_accuracy: 0.6300\n",
      "Epoch 95/500\n",
      " - 0s - loss: 0.0491 - accuracy: 0.6939 - val_loss: 0.0587 - val_accuracy: 0.6150\n",
      "Epoch 96/500\n",
      " - 0s - loss: 0.0495 - accuracy: 0.6822 - val_loss: 0.0589 - val_accuracy: 0.6175\n",
      "Epoch 97/500\n",
      " - 0s - loss: 0.0496 - accuracy: 0.6781 - val_loss: 0.0588 - val_accuracy: 0.6300\n",
      "Epoch 98/500\n",
      " - 0s - loss: 0.0496 - accuracy: 0.6847 - val_loss: 0.0585 - val_accuracy: 0.6300\n",
      "Epoch 99/500\n",
      " - 0s - loss: 0.0493 - accuracy: 0.6856 - val_loss: 0.0583 - val_accuracy: 0.6350\n",
      "Epoch 100/500\n",
      " - 0s - loss: 0.0496 - accuracy: 0.6881 - val_loss: 0.0583 - val_accuracy: 0.6375\n",
      "Epoch 101/500\n",
      " - 0s - loss: 0.0491 - accuracy: 0.7006 - val_loss: 0.0585 - val_accuracy: 0.6425\n",
      "Epoch 102/500\n",
      " - 0s - loss: 0.0496 - accuracy: 0.6756 - val_loss: 0.0588 - val_accuracy: 0.6450\n",
      "Epoch 103/500\n",
      " - 0s - loss: 0.0485 - accuracy: 0.7048 - val_loss: 0.0589 - val_accuracy: 0.6450\n",
      "Epoch 104/500\n",
      " - 0s - loss: 0.0488 - accuracy: 0.6922 - val_loss: 0.0589 - val_accuracy: 0.6350\n",
      "Epoch 105/500\n",
      " - 0s - loss: 0.0493 - accuracy: 0.6839 - val_loss: 0.0587 - val_accuracy: 0.6375\n",
      "Epoch 106/500\n",
      " - 0s - loss: 0.0490 - accuracy: 0.6997 - val_loss: 0.0586 - val_accuracy: 0.6400\n",
      "Epoch 107/500\n",
      " - 0s - loss: 0.0484 - accuracy: 0.7006 - val_loss: 0.0586 - val_accuracy: 0.6400\n",
      "Epoch 108/500\n",
      " - 0s - loss: 0.0488 - accuracy: 0.7064 - val_loss: 0.0585 - val_accuracy: 0.6425\n",
      "Epoch 109/500\n",
      " - 0s - loss: 0.0484 - accuracy: 0.6989 - val_loss: 0.0584 - val_accuracy: 0.6475\n",
      "Epoch 110/500\n",
      " - 0s - loss: 0.0482 - accuracy: 0.6939 - val_loss: 0.0583 - val_accuracy: 0.6400\n",
      "Epoch 111/500\n",
      " - 0s - loss: 0.0485 - accuracy: 0.6897 - val_loss: 0.0581 - val_accuracy: 0.6450\n",
      "Epoch 112/500\n",
      " - 0s - loss: 0.0483 - accuracy: 0.6889 - val_loss: 0.0583 - val_accuracy: 0.6350\n",
      "Epoch 113/500\n",
      " - 0s - loss: 0.0478 - accuracy: 0.7073 - val_loss: 0.0584 - val_accuracy: 0.6300\n",
      "Epoch 114/500\n",
      " - 0s - loss: 0.0481 - accuracy: 0.6931 - val_loss: 0.0586 - val_accuracy: 0.6250\n",
      "Epoch 115/500\n",
      " - 0s - loss: 0.0481 - accuracy: 0.7081 - val_loss: 0.0588 - val_accuracy: 0.6225\n",
      "Epoch 116/500\n",
      " - 0s - loss: 0.0474 - accuracy: 0.7081 - val_loss: 0.0589 - val_accuracy: 0.6250\n",
      "Epoch 117/500\n",
      " - 0s - loss: 0.0475 - accuracy: 0.7006 - val_loss: 0.0591 - val_accuracy: 0.6275\n",
      "Epoch 118/500\n",
      " - 0s - loss: 0.0467 - accuracy: 0.7173 - val_loss: 0.0591 - val_accuracy: 0.6300\n",
      "Epoch 119/500\n",
      " - 0s - loss: 0.0476 - accuracy: 0.7023 - val_loss: 0.0590 - val_accuracy: 0.6400\n",
      "Epoch 120/500\n",
      " - 0s - loss: 0.0470 - accuracy: 0.7048 - val_loss: 0.0589 - val_accuracy: 0.6350\n",
      "Epoch 121/500\n",
      " - 0s - loss: 0.0470 - accuracy: 0.7081 - val_loss: 0.0588 - val_accuracy: 0.6325\n",
      "Epoch 122/500\n",
      " - 0s - loss: 0.0470 - accuracy: 0.7089 - val_loss: 0.0589 - val_accuracy: 0.6400\n",
      "Epoch 123/500\n",
      " - 0s - loss: 0.0471 - accuracy: 0.7006 - val_loss: 0.0590 - val_accuracy: 0.6375\n",
      "Epoch 124/500\n",
      " - 0s - loss: 0.0462 - accuracy: 0.7181 - val_loss: 0.0590 - val_accuracy: 0.6375\n",
      "Epoch 125/500\n",
      " - 0s - loss: 0.0470 - accuracy: 0.7056 - val_loss: 0.0590 - val_accuracy: 0.6375\n",
      "Epoch 126/500\n",
      " - 0s - loss: 0.0471 - accuracy: 0.7131 - val_loss: 0.0590 - val_accuracy: 0.6300\n",
      "Epoch 127/500\n",
      " - 0s - loss: 0.0466 - accuracy: 0.7156 - val_loss: 0.0590 - val_accuracy: 0.6350\n",
      "Epoch 128/500\n",
      " - 0s - loss: 0.0466 - accuracy: 0.7131 - val_loss: 0.0590 - val_accuracy: 0.6325\n",
      "Epoch 129/500\n",
      " - 0s - loss: 0.0474 - accuracy: 0.7106 - val_loss: 0.0590 - val_accuracy: 0.6325\n",
      "Epoch 130/500\n",
      " - 0s - loss: 0.0469 - accuracy: 0.7189 - val_loss: 0.0590 - val_accuracy: 0.6450\n",
      "Epoch 131/500\n",
      " - 0s - loss: 0.0468 - accuracy: 0.7098 - val_loss: 0.0591 - val_accuracy: 0.6525\n",
      "Epoch 132/500\n",
      " - 0s - loss: 0.0465 - accuracy: 0.7048 - val_loss: 0.0590 - val_accuracy: 0.6375\n",
      "Epoch 133/500\n",
      " - 0s - loss: 0.0455 - accuracy: 0.7264 - val_loss: 0.0590 - val_accuracy: 0.6325\n",
      "Epoch 134/500\n",
      " - 0s - loss: 0.0468 - accuracy: 0.7089 - val_loss: 0.0591 - val_accuracy: 0.6350\n",
      "Epoch 135/500\n",
      " - 0s - loss: 0.0451 - accuracy: 0.7273 - val_loss: 0.0592 - val_accuracy: 0.6300\n",
      "Epoch 136/500\n",
      " - 0s - loss: 0.0469 - accuracy: 0.6981 - val_loss: 0.0593 - val_accuracy: 0.6275\n",
      "Epoch 137/500\n",
      " - 0s - loss: 0.0463 - accuracy: 0.7189 - val_loss: 0.0593 - val_accuracy: 0.6350\n",
      "Epoch 138/500\n",
      " - 0s - loss: 0.0457 - accuracy: 0.7189 - val_loss: 0.0592 - val_accuracy: 0.6225\n",
      "Epoch 139/500\n",
      " - 0s - loss: 0.0460 - accuracy: 0.7089 - val_loss: 0.0591 - val_accuracy: 0.6325\n",
      "Epoch 140/500\n",
      " - 0s - loss: 0.0453 - accuracy: 0.7314 - val_loss: 0.0590 - val_accuracy: 0.6300\n",
      "Epoch 141/500\n",
      " - 0s - loss: 0.0463 - accuracy: 0.7131 - val_loss: 0.0589 - val_accuracy: 0.6325\n",
      "Epoch 142/500\n",
      " - 0s - loss: 0.0449 - accuracy: 0.7298 - val_loss: 0.0590 - val_accuracy: 0.6275\n",
      "Epoch 143/500\n",
      " - 0s - loss: 0.0462 - accuracy: 0.7089 - val_loss: 0.0590 - val_accuracy: 0.6375\n",
      "Epoch 144/500\n",
      " - 0s - loss: 0.0452 - accuracy: 0.7123 - val_loss: 0.0590 - val_accuracy: 0.6325\n",
      "Epoch 145/500\n",
      " - 0s - loss: 0.0452 - accuracy: 0.7198 - val_loss: 0.0589 - val_accuracy: 0.6275\n",
      "Epoch 146/500\n",
      " - 0s - loss: 0.0449 - accuracy: 0.7264 - val_loss: 0.0588 - val_accuracy: 0.6325\n",
      "Epoch 147/500\n",
      " - 0s - loss: 0.0461 - accuracy: 0.7164 - val_loss: 0.0589 - val_accuracy: 0.6400\n",
      "Epoch 148/500\n",
      " - 0s - loss: 0.0454 - accuracy: 0.7223 - val_loss: 0.0591 - val_accuracy: 0.6450\n",
      "Epoch 149/500\n",
      " - 0s - loss: 0.0449 - accuracy: 0.7314 - val_loss: 0.0593 - val_accuracy: 0.6425\n",
      "Epoch 150/500\n",
      " - 0s - loss: 0.0451 - accuracy: 0.7289 - val_loss: 0.0594 - val_accuracy: 0.6325\n",
      "Epoch 151/500\n",
      " - 0s - loss: 0.0451 - accuracy: 0.7256 - val_loss: 0.0594 - val_accuracy: 0.6350\n",
      "Epoch 152/500\n",
      " - 0s - loss: 0.0448 - accuracy: 0.7364 - val_loss: 0.0592 - val_accuracy: 0.6375\n",
      "Epoch 153/500\n",
      " - 0s - loss: 0.0449 - accuracy: 0.7339 - val_loss: 0.0592 - val_accuracy: 0.6300\n",
      "Epoch 154/500\n",
      " - 0s - loss: 0.0449 - accuracy: 0.7223 - val_loss: 0.0593 - val_accuracy: 0.6225\n",
      "Epoch 155/500\n",
      " - 0s - loss: 0.0447 - accuracy: 0.7173 - val_loss: 0.0594 - val_accuracy: 0.6250\n",
      "Epoch 156/500\n",
      " - 0s - loss: 0.0452 - accuracy: 0.7264 - val_loss: 0.0596 - val_accuracy: 0.6325\n",
      "Epoch 157/500\n",
      " - 0s - loss: 0.0445 - accuracy: 0.7289 - val_loss: 0.0598 - val_accuracy: 0.6325\n",
      "Epoch 158/500\n",
      " - 0s - loss: 0.0442 - accuracy: 0.7448 - val_loss: 0.0597 - val_accuracy: 0.6325\n",
      "Epoch 159/500\n",
      " - 0s - loss: 0.0439 - accuracy: 0.7289 - val_loss: 0.0595 - val_accuracy: 0.6275\n",
      "Epoch 160/500\n",
      " - 0s - loss: 0.0438 - accuracy: 0.7431 - val_loss: 0.0594 - val_accuracy: 0.6325\n",
      "Epoch 161/500\n",
      " - 0s - loss: 0.0443 - accuracy: 0.7389 - val_loss: 0.0593 - val_accuracy: 0.6325\n",
      "Epoch 162/500\n",
      " - 0s - loss: 0.0442 - accuracy: 0.7273 - val_loss: 0.0594 - val_accuracy: 0.6325\n",
      "Epoch 163/500\n",
      " - 0s - loss: 0.0438 - accuracy: 0.7406 - val_loss: 0.0596 - val_accuracy: 0.6325\n",
      "Epoch 164/500\n",
      " - 0s - loss: 0.0438 - accuracy: 0.7364 - val_loss: 0.0596 - val_accuracy: 0.6325\n",
      "Epoch 165/500\n",
      " - 0s - loss: 0.0432 - accuracy: 0.7473 - val_loss: 0.0595 - val_accuracy: 0.6250\n",
      "Epoch 166/500\n",
      " - 0s - loss: 0.0437 - accuracy: 0.7465 - val_loss: 0.0594 - val_accuracy: 0.6300\n",
      "Epoch 167/500\n",
      " - 0s - loss: 0.0444 - accuracy: 0.7389 - val_loss: 0.0594 - val_accuracy: 0.6325\n",
      "Epoch 168/500\n",
      " - 0s - loss: 0.0440 - accuracy: 0.7548 - val_loss: 0.0593 - val_accuracy: 0.6450\n",
      "Epoch 169/500\n",
      " - 0s - loss: 0.0439 - accuracy: 0.7289 - val_loss: 0.0591 - val_accuracy: 0.6400\n",
      "Epoch 170/500\n",
      " - 0s - loss: 0.0439 - accuracy: 0.7306 - val_loss: 0.0591 - val_accuracy: 0.6325\n",
      "Epoch 171/500\n",
      " - 0s - loss: 0.0435 - accuracy: 0.7456 - val_loss: 0.0591 - val_accuracy: 0.6325\n",
      "Epoch 172/500\n",
      " - 0s - loss: 0.0434 - accuracy: 0.7331 - val_loss: 0.0591 - val_accuracy: 0.6375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/500\n",
      " - 0s - loss: 0.0441 - accuracy: 0.7339 - val_loss: 0.0593 - val_accuracy: 0.6400\n",
      "Epoch 174/500\n",
      " - 0s - loss: 0.0431 - accuracy: 0.7490 - val_loss: 0.0594 - val_accuracy: 0.6325\n",
      "Epoch 175/500\n",
      " - 0s - loss: 0.0428 - accuracy: 0.7406 - val_loss: 0.0596 - val_accuracy: 0.6350\n",
      "Epoch 176/500\n",
      " - 0s - loss: 0.0431 - accuracy: 0.7440 - val_loss: 0.0598 - val_accuracy: 0.6300\n",
      "Epoch 177/500\n",
      " - 0s - loss: 0.0429 - accuracy: 0.7523 - val_loss: 0.0598 - val_accuracy: 0.6350\n",
      "Epoch 178/500\n",
      " - 0s - loss: 0.0423 - accuracy: 0.7448 - val_loss: 0.0599 - val_accuracy: 0.6325\n",
      "Epoch 179/500\n",
      " - 0s - loss: 0.0428 - accuracy: 0.7406 - val_loss: 0.0599 - val_accuracy: 0.6300\n",
      "Epoch 180/500\n",
      " - 0s - loss: 0.0429 - accuracy: 0.7531 - val_loss: 0.0596 - val_accuracy: 0.6375\n",
      "Epoch 181/500\n",
      " - 0s - loss: 0.0431 - accuracy: 0.7473 - val_loss: 0.0593 - val_accuracy: 0.6400\n",
      "Epoch 182/500\n",
      " - 0s - loss: 0.0431 - accuracy: 0.7565 - val_loss: 0.0590 - val_accuracy: 0.6475\n",
      "Epoch 183/500\n",
      " - 0s - loss: 0.0424 - accuracy: 0.7506 - val_loss: 0.0590 - val_accuracy: 0.6475\n",
      "Epoch 184/500\n",
      " - 0s - loss: 0.0425 - accuracy: 0.7498 - val_loss: 0.0591 - val_accuracy: 0.6500\n",
      "Epoch 185/500\n",
      " - 0s - loss: 0.0423 - accuracy: 0.7531 - val_loss: 0.0592 - val_accuracy: 0.6475\n",
      "Epoch 186/500\n",
      " - 0s - loss: 0.0422 - accuracy: 0.7506 - val_loss: 0.0592 - val_accuracy: 0.6425\n",
      "Epoch 187/500\n",
      " - 0s - loss: 0.0417 - accuracy: 0.7573 - val_loss: 0.0593 - val_accuracy: 0.6475\n",
      "Epoch 188/500\n",
      " - 0s - loss: 0.0418 - accuracy: 0.7465 - val_loss: 0.0594 - val_accuracy: 0.6500\n",
      "Epoch 189/500\n",
      " - 0s - loss: 0.0420 - accuracy: 0.7615 - val_loss: 0.0594 - val_accuracy: 0.6475\n",
      "Epoch 190/500\n",
      " - 0s - loss: 0.0420 - accuracy: 0.7540 - val_loss: 0.0593 - val_accuracy: 0.6550\n",
      "Epoch 191/500\n",
      " - 0s - loss: 0.0424 - accuracy: 0.7573 - val_loss: 0.0591 - val_accuracy: 0.6550\n",
      "Epoch 192/500\n",
      " - 0s - loss: 0.0420 - accuracy: 0.7498 - val_loss: 0.0589 - val_accuracy: 0.6450\n",
      "Epoch 193/500\n",
      " - 0s - loss: 0.0424 - accuracy: 0.7456 - val_loss: 0.0590 - val_accuracy: 0.6350\n",
      "Epoch 194/500\n",
      " - 0s - loss: 0.0418 - accuracy: 0.7490 - val_loss: 0.0592 - val_accuracy: 0.6400\n",
      "Epoch 195/500\n",
      " - 0s - loss: 0.0420 - accuracy: 0.7523 - val_loss: 0.0591 - val_accuracy: 0.6450\n",
      "Epoch 196/500\n",
      " - 0s - loss: 0.0421 - accuracy: 0.7531 - val_loss: 0.0590 - val_accuracy: 0.6500\n",
      "Epoch 197/500\n",
      " - 0s - loss: 0.0409 - accuracy: 0.7573 - val_loss: 0.0589 - val_accuracy: 0.6575\n",
      "Epoch 198/500\n",
      " - 0s - loss: 0.0419 - accuracy: 0.7498 - val_loss: 0.0587 - val_accuracy: 0.6475\n",
      "Epoch 199/500\n",
      " - 0s - loss: 0.0424 - accuracy: 0.7356 - val_loss: 0.0586 - val_accuracy: 0.6375\n",
      "Epoch 200/500\n",
      " - 0s - loss: 0.0414 - accuracy: 0.7565 - val_loss: 0.0586 - val_accuracy: 0.6475\n",
      "Epoch 201/500\n",
      " - 0s - loss: 0.0409 - accuracy: 0.7681 - val_loss: 0.0587 - val_accuracy: 0.6550\n",
      "Epoch 202/500\n",
      " - 0s - loss: 0.0404 - accuracy: 0.7656 - val_loss: 0.0590 - val_accuracy: 0.6475\n",
      "Epoch 203/500\n",
      " - 0s - loss: 0.0411 - accuracy: 0.7606 - val_loss: 0.0591 - val_accuracy: 0.6425\n",
      "Epoch 204/500\n",
      " - 0s - loss: 0.0419 - accuracy: 0.7623 - val_loss: 0.0590 - val_accuracy: 0.6450\n",
      "Epoch 205/500\n",
      " - 0s - loss: 0.0408 - accuracy: 0.7531 - val_loss: 0.0589 - val_accuracy: 0.6475\n",
      "Epoch 206/500\n",
      " - 0s - loss: 0.0406 - accuracy: 0.7715 - val_loss: 0.0589 - val_accuracy: 0.6400\n",
      "Epoch 207/500\n",
      " - 0s - loss: 0.0413 - accuracy: 0.7531 - val_loss: 0.0592 - val_accuracy: 0.6550\n",
      "Epoch 208/500\n",
      " - 0s - loss: 0.0405 - accuracy: 0.7690 - val_loss: 0.0596 - val_accuracy: 0.6525\n",
      "Epoch 209/500\n",
      " - 0s - loss: 0.0421 - accuracy: 0.7415 - val_loss: 0.0593 - val_accuracy: 0.6375\n",
      "Epoch 210/500\n",
      " - 0s - loss: 0.0413 - accuracy: 0.7606 - val_loss: 0.0597 - val_accuracy: 0.6375\n",
      "Epoch 211/500\n",
      " - 0s - loss: 0.0405 - accuracy: 0.7681 - val_loss: 0.0593 - val_accuracy: 0.6475\n",
      "Epoch 212/500\n",
      " - 0s - loss: 0.0412 - accuracy: 0.7498 - val_loss: 0.0594 - val_accuracy: 0.6525\n",
      "Epoch 213/500\n",
      " - 0s - loss: 0.0409 - accuracy: 0.7548 - val_loss: 0.0588 - val_accuracy: 0.6450\n",
      "Epoch 214/500\n",
      " - 0s - loss: 0.0407 - accuracy: 0.7740 - val_loss: 0.0588 - val_accuracy: 0.6500\n",
      "Epoch 215/500\n",
      " - 0s - loss: 0.0409 - accuracy: 0.7581 - val_loss: 0.0588 - val_accuracy: 0.6425\n",
      "Epoch 216/500\n",
      " - 0s - loss: 0.0412 - accuracy: 0.7548 - val_loss: 0.0595 - val_accuracy: 0.6475\n",
      "Epoch 217/500\n",
      " - 0s - loss: 0.0411 - accuracy: 0.7665 - val_loss: 0.0595 - val_accuracy: 0.6450\n",
      "Epoch 218/500\n",
      " - 0s - loss: 0.0406 - accuracy: 0.7648 - val_loss: 0.0595 - val_accuracy: 0.6525\n",
      "Epoch 219/500\n",
      " - 0s - loss: 0.0410 - accuracy: 0.7606 - val_loss: 0.0593 - val_accuracy: 0.6450\n",
      "Epoch 220/500\n",
      " - 0s - loss: 0.0407 - accuracy: 0.7581 - val_loss: 0.0590 - val_accuracy: 0.6350\n",
      "Epoch 221/500\n",
      " - 0s - loss: 0.0401 - accuracy: 0.7731 - val_loss: 0.0591 - val_accuracy: 0.6375\n",
      "Epoch 222/500\n",
      " - 0s - loss: 0.0396 - accuracy: 0.7781 - val_loss: 0.0591 - val_accuracy: 0.6400\n",
      "Epoch 223/500\n",
      " - 0s - loss: 0.0397 - accuracy: 0.7740 - val_loss: 0.0592 - val_accuracy: 0.6450\n",
      "Epoch 224/500\n",
      " - 0s - loss: 0.0394 - accuracy: 0.7748 - val_loss: 0.0592 - val_accuracy: 0.6400\n",
      "Epoch 225/500\n",
      " - 0s - loss: 0.0404 - accuracy: 0.7615 - val_loss: 0.0593 - val_accuracy: 0.6400\n",
      "Epoch 226/500\n",
      " - 0s - loss: 0.0389 - accuracy: 0.7823 - val_loss: 0.0593 - val_accuracy: 0.6325\n",
      "Epoch 227/500\n",
      " - 0s - loss: 0.0392 - accuracy: 0.7731 - val_loss: 0.0590 - val_accuracy: 0.6325\n",
      "Epoch 228/500\n",
      " - 0s - loss: 0.0394 - accuracy: 0.7715 - val_loss: 0.0590 - val_accuracy: 0.6375\n",
      "Epoch 229/500\n",
      " - 0s - loss: 0.0401 - accuracy: 0.7615 - val_loss: 0.0591 - val_accuracy: 0.6350\n",
      "Epoch 230/500\n",
      " - 0s - loss: 0.0401 - accuracy: 0.7648 - val_loss: 0.0592 - val_accuracy: 0.6350\n",
      "Epoch 231/500\n",
      " - 0s - loss: 0.0405 - accuracy: 0.7631 - val_loss: 0.0593 - val_accuracy: 0.6250\n",
      "Epoch 232/500\n",
      " - 0s - loss: 0.0389 - accuracy: 0.7748 - val_loss: 0.0595 - val_accuracy: 0.6300\n",
      "Epoch 233/500\n",
      " - 0s - loss: 0.0383 - accuracy: 0.7865 - val_loss: 0.0594 - val_accuracy: 0.6275\n",
      "Epoch 234/500\n",
      " - 0s - loss: 0.0392 - accuracy: 0.7706 - val_loss: 0.0593 - val_accuracy: 0.6375\n",
      "Epoch 235/500\n",
      " - 0s - loss: 0.0383 - accuracy: 0.7781 - val_loss: 0.0593 - val_accuracy: 0.6375\n",
      "Epoch 236/500\n",
      " - 0s - loss: 0.0389 - accuracy: 0.7748 - val_loss: 0.0593 - val_accuracy: 0.6450\n",
      "Epoch 237/500\n",
      " - 0s - loss: 0.0395 - accuracy: 0.7740 - val_loss: 0.0594 - val_accuracy: 0.6425\n",
      "Epoch 238/500\n",
      " - 0s - loss: 0.0396 - accuracy: 0.7681 - val_loss: 0.0594 - val_accuracy: 0.6450\n",
      "Epoch 239/500\n",
      " - 0s - loss: 0.0401 - accuracy: 0.7665 - val_loss: 0.0592 - val_accuracy: 0.6475\n",
      "Epoch 240/500\n",
      " - 0s - loss: 0.0391 - accuracy: 0.7815 - val_loss: 0.0592 - val_accuracy: 0.6375\n",
      "Epoch 241/500\n",
      " - 0s - loss: 0.0386 - accuracy: 0.7840 - val_loss: 0.0593 - val_accuracy: 0.6375\n",
      "Epoch 242/500\n",
      " - 0s - loss: 0.0392 - accuracy: 0.7706 - val_loss: 0.0593 - val_accuracy: 0.6375\n",
      "Epoch 243/500\n",
      " - 0s - loss: 0.0388 - accuracy: 0.7740 - val_loss: 0.0593 - val_accuracy: 0.6400\n",
      "Epoch 244/500\n",
      " - 0s - loss: 0.0383 - accuracy: 0.7798 - val_loss: 0.0595 - val_accuracy: 0.6375\n",
      "Epoch 245/500\n",
      " - 0s - loss: 0.0384 - accuracy: 0.7765 - val_loss: 0.0595 - val_accuracy: 0.6400\n",
      "Epoch 246/500\n",
      " - 0s - loss: 0.0386 - accuracy: 0.7740 - val_loss: 0.0594 - val_accuracy: 0.6325\n",
      "Epoch 247/500\n",
      " - 0s - loss: 0.0384 - accuracy: 0.7807 - val_loss: 0.0594 - val_accuracy: 0.6325\n",
      "Epoch 248/500\n",
      " - 0s - loss: 0.0377 - accuracy: 0.7940 - val_loss: 0.0594 - val_accuracy: 0.6200\n",
      "Epoch 249/500\n",
      " - 0s - loss: 0.0384 - accuracy: 0.7823 - val_loss: 0.0596 - val_accuracy: 0.6275\n",
      "Epoch 250/500\n",
      " - 0s - loss: 0.0390 - accuracy: 0.7790 - val_loss: 0.0597 - val_accuracy: 0.6300\n",
      "Epoch 251/500\n",
      " - 0s - loss: 0.0377 - accuracy: 0.7781 - val_loss: 0.0596 - val_accuracy: 0.6325\n",
      "Epoch 252/500\n",
      " - 0s - loss: 0.0384 - accuracy: 0.7823 - val_loss: 0.0596 - val_accuracy: 0.6300\n",
      "Epoch 253/500\n",
      " - 0s - loss: 0.0386 - accuracy: 0.7723 - val_loss: 0.0596 - val_accuracy: 0.6325\n",
      "Epoch 254/500\n",
      " - 0s - loss: 0.0385 - accuracy: 0.7848 - val_loss: 0.0595 - val_accuracy: 0.6375\n",
      "Epoch 255/500\n",
      " - 0s - loss: 0.0386 - accuracy: 0.7823 - val_loss: 0.0593 - val_accuracy: 0.6350\n",
      "Epoch 256/500\n",
      " - 0s - loss: 0.0379 - accuracy: 0.7840 - val_loss: 0.0592 - val_accuracy: 0.6375\n",
      "Epoch 257/500\n",
      " - 0s - loss: 0.0377 - accuracy: 0.7957 - val_loss: 0.0590 - val_accuracy: 0.6425\n",
      "Epoch 258/500\n",
      " - 0s - loss: 0.0379 - accuracy: 0.7932 - val_loss: 0.0591 - val_accuracy: 0.6425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/500\n",
      " - 0s - loss: 0.0383 - accuracy: 0.7756 - val_loss: 0.0591 - val_accuracy: 0.6425\n",
      "Epoch 260/500\n",
      " - 0s - loss: 0.0384 - accuracy: 0.7807 - val_loss: 0.0591 - val_accuracy: 0.6425\n",
      "Epoch 261/500\n",
      " - 0s - loss: 0.0376 - accuracy: 0.7907 - val_loss: 0.0594 - val_accuracy: 0.6450\n",
      "Epoch 262/500\n",
      " - 0s - loss: 0.0374 - accuracy: 0.7907 - val_loss: 0.0593 - val_accuracy: 0.6450\n",
      "Epoch 263/500\n",
      " - 0s - loss: 0.0377 - accuracy: 0.7907 - val_loss: 0.0591 - val_accuracy: 0.6550\n",
      "Epoch 264/500\n",
      " - 0s - loss: 0.0373 - accuracy: 0.7873 - val_loss: 0.0591 - val_accuracy: 0.6550\n",
      "Epoch 265/500\n",
      " - 0s - loss: 0.0369 - accuracy: 0.7873 - val_loss: 0.0593 - val_accuracy: 0.6525\n",
      "Epoch 266/500\n",
      " - 0s - loss: 0.0371 - accuracy: 0.7857 - val_loss: 0.0593 - val_accuracy: 0.6525\n",
      "Epoch 267/500\n",
      " - 0s - loss: 0.0363 - accuracy: 0.7973 - val_loss: 0.0594 - val_accuracy: 0.6450\n",
      "Epoch 268/500\n",
      " - 0s - loss: 0.0376 - accuracy: 0.7873 - val_loss: 0.0592 - val_accuracy: 0.6475\n",
      "Epoch 269/500\n",
      " - 0s - loss: 0.0369 - accuracy: 0.7882 - val_loss: 0.0591 - val_accuracy: 0.6475\n",
      "Epoch 270/500\n",
      " - 0s - loss: 0.0381 - accuracy: 0.7756 - val_loss: 0.0591 - val_accuracy: 0.6400\n",
      "Epoch 271/500\n",
      " - 0s - loss: 0.0376 - accuracy: 0.7890 - val_loss: 0.0591 - val_accuracy: 0.6475\n",
      "Epoch 272/500\n",
      " - 0s - loss: 0.0375 - accuracy: 0.7915 - val_loss: 0.0592 - val_accuracy: 0.6475\n",
      "Epoch 273/500\n",
      " - 0s - loss: 0.0372 - accuracy: 0.7873 - val_loss: 0.0595 - val_accuracy: 0.6375\n",
      "Epoch 274/500\n",
      " - 0s - loss: 0.0367 - accuracy: 0.7932 - val_loss: 0.0597 - val_accuracy: 0.6250\n",
      "Epoch 275/500\n",
      " - 0s - loss: 0.0372 - accuracy: 0.7932 - val_loss: 0.0598 - val_accuracy: 0.6275\n",
      "Epoch 276/500\n",
      " - 0s - loss: 0.0370 - accuracy: 0.7848 - val_loss: 0.0597 - val_accuracy: 0.6425\n",
      "Epoch 277/500\n",
      " - 0s - loss: 0.0365 - accuracy: 0.7957 - val_loss: 0.0595 - val_accuracy: 0.6525\n",
      "Epoch 278/500\n",
      " - 0s - loss: 0.0371 - accuracy: 0.7882 - val_loss: 0.0593 - val_accuracy: 0.6575\n",
      "Epoch 279/500\n",
      " - 0s - loss: 0.0377 - accuracy: 0.7923 - val_loss: 0.0591 - val_accuracy: 0.6575\n",
      "Epoch 280/500\n",
      " - 0s - loss: 0.0374 - accuracy: 0.7848 - val_loss: 0.0591 - val_accuracy: 0.6650\n",
      "Epoch 281/500\n",
      " - 0s - loss: 0.0371 - accuracy: 0.7990 - val_loss: 0.0593 - val_accuracy: 0.6550\n",
      "Epoch 282/500\n",
      " - 0s - loss: 0.0353 - accuracy: 0.7973 - val_loss: 0.0596 - val_accuracy: 0.6425\n",
      "Epoch 283/500\n",
      " - 0s - loss: 0.0358 - accuracy: 0.8040 - val_loss: 0.0600 - val_accuracy: 0.6550\n",
      "Epoch 284/500\n",
      " - 0s - loss: 0.0367 - accuracy: 0.7857 - val_loss: 0.0602 - val_accuracy: 0.6325\n",
      "Epoch 285/500\n",
      " - 0s - loss: 0.0370 - accuracy: 0.7890 - val_loss: 0.0603 - val_accuracy: 0.6375\n",
      "Epoch 286/500\n",
      " - 0s - loss: 0.0363 - accuracy: 0.7932 - val_loss: 0.0602 - val_accuracy: 0.6325\n",
      "Epoch 287/500\n",
      " - 0s - loss: 0.0365 - accuracy: 0.7965 - val_loss: 0.0602 - val_accuracy: 0.6500\n",
      "Epoch 288/500\n",
      " - 0s - loss: 0.0366 - accuracy: 0.7965 - val_loss: 0.0597 - val_accuracy: 0.6375\n",
      "Epoch 289/500\n",
      " - 0s - loss: 0.0362 - accuracy: 0.7948 - val_loss: 0.0597 - val_accuracy: 0.6550\n",
      "Epoch 290/500\n",
      " - 0s - loss: 0.0363 - accuracy: 0.7865 - val_loss: 0.0595 - val_accuracy: 0.6525\n",
      "Epoch 291/500\n",
      " - 0s - loss: 0.0357 - accuracy: 0.8065 - val_loss: 0.0598 - val_accuracy: 0.6450\n",
      "Epoch 292/500\n",
      " - 0s - loss: 0.0362 - accuracy: 0.7965 - val_loss: 0.0601 - val_accuracy: 0.6450\n",
      "Epoch 293/500\n",
      " - 0s - loss: 0.0371 - accuracy: 0.7857 - val_loss: 0.0603 - val_accuracy: 0.6475\n",
      "Epoch 294/500\n",
      " - 0s - loss: 0.0367 - accuracy: 0.7873 - val_loss: 0.0604 - val_accuracy: 0.6400\n",
      "Epoch 295/500\n",
      " - 0s - loss: 0.0360 - accuracy: 0.7982 - val_loss: 0.0602 - val_accuracy: 0.6425\n",
      "Epoch 296/500\n",
      " - 0s - loss: 0.0359 - accuracy: 0.8048 - val_loss: 0.0602 - val_accuracy: 0.6400\n",
      "Epoch 297/500\n",
      " - 0s - loss: 0.0364 - accuracy: 0.7907 - val_loss: 0.0600 - val_accuracy: 0.6475\n",
      "Epoch 298/500\n",
      " - 0s - loss: 0.0357 - accuracy: 0.7982 - val_loss: 0.0600 - val_accuracy: 0.6475\n",
      "Epoch 299/500\n",
      " - 0s - loss: 0.0367 - accuracy: 0.7965 - val_loss: 0.0600 - val_accuracy: 0.6375\n",
      "Epoch 300/500\n",
      " - 0s - loss: 0.0354 - accuracy: 0.8007 - val_loss: 0.0600 - val_accuracy: 0.6400\n",
      "Epoch 301/500\n",
      " - 0s - loss: 0.0359 - accuracy: 0.7873 - val_loss: 0.0603 - val_accuracy: 0.6525\n",
      "Epoch 302/500\n",
      " - 0s - loss: 0.0342 - accuracy: 0.8107 - val_loss: 0.0601 - val_accuracy: 0.6400\n",
      "Epoch 303/500\n",
      " - 0s - loss: 0.0358 - accuracy: 0.7973 - val_loss: 0.0599 - val_accuracy: 0.6450\n",
      "Epoch 304/500\n",
      " - 0s - loss: 0.0371 - accuracy: 0.7915 - val_loss: 0.0597 - val_accuracy: 0.6475\n",
      "Epoch 305/500\n",
      " - 0s - loss: 0.0352 - accuracy: 0.8098 - val_loss: 0.0597 - val_accuracy: 0.6450\n",
      "Epoch 306/500\n",
      " - 0s - loss: 0.0361 - accuracy: 0.8007 - val_loss: 0.0597 - val_accuracy: 0.6450\n",
      "Epoch 307/500\n",
      " - 0s - loss: 0.0348 - accuracy: 0.8057 - val_loss: 0.0600 - val_accuracy: 0.6450\n",
      "Epoch 308/500\n",
      " - 0s - loss: 0.0358 - accuracy: 0.7990 - val_loss: 0.0602 - val_accuracy: 0.6475\n",
      "Epoch 309/500\n",
      " - 0s - loss: 0.0350 - accuracy: 0.8065 - val_loss: 0.0600 - val_accuracy: 0.6425\n",
      "Epoch 310/500\n",
      " - 0s - loss: 0.0343 - accuracy: 0.8132 - val_loss: 0.0600 - val_accuracy: 0.6550\n",
      "Epoch 311/500\n",
      " - 0s - loss: 0.0353 - accuracy: 0.7957 - val_loss: 0.0599 - val_accuracy: 0.6400\n",
      "Epoch 312/500\n",
      " - 0s - loss: 0.0359 - accuracy: 0.8023 - val_loss: 0.0602 - val_accuracy: 0.6425\n",
      "Epoch 313/500\n",
      " - 0s - loss: 0.0362 - accuracy: 0.7957 - val_loss: 0.0602 - val_accuracy: 0.6400\n",
      "Epoch 314/500\n",
      " - 0s - loss: 0.0367 - accuracy: 0.7940 - val_loss: 0.0604 - val_accuracy: 0.6350\n",
      "Epoch 315/500\n",
      " - 0s - loss: 0.0350 - accuracy: 0.8040 - val_loss: 0.0604 - val_accuracy: 0.6350\n",
      "Epoch 316/500\n",
      " - 0s - loss: 0.0341 - accuracy: 0.8140 - val_loss: 0.0602 - val_accuracy: 0.6350\n",
      "Epoch 317/500\n",
      " - 0s - loss: 0.0357 - accuracy: 0.7990 - val_loss: 0.0600 - val_accuracy: 0.6425\n",
      "Epoch 318/500\n",
      " - 0s - loss: 0.0351 - accuracy: 0.7957 - val_loss: 0.0600 - val_accuracy: 0.6425\n",
      "Epoch 319/500\n",
      " - 0s - loss: 0.0347 - accuracy: 0.8057 - val_loss: 0.0601 - val_accuracy: 0.6425\n",
      "Epoch 320/500\n",
      " - 0s - loss: 0.0345 - accuracy: 0.8090 - val_loss: 0.0602 - val_accuracy: 0.6475\n",
      "Epoch 321/500\n",
      " - 0s - loss: 0.0348 - accuracy: 0.8123 - val_loss: 0.0603 - val_accuracy: 0.6425\n",
      "Epoch 322/500\n",
      " - 0s - loss: 0.0339 - accuracy: 0.8132 - val_loss: 0.0605 - val_accuracy: 0.6425\n",
      "Epoch 323/500\n",
      " - 0s - loss: 0.0346 - accuracy: 0.8132 - val_loss: 0.0603 - val_accuracy: 0.6450\n",
      "Epoch 324/500\n",
      " - 0s - loss: 0.0346 - accuracy: 0.8123 - val_loss: 0.0602 - val_accuracy: 0.6400\n",
      "Epoch 325/500\n",
      " - 0s - loss: 0.0348 - accuracy: 0.8107 - val_loss: 0.0601 - val_accuracy: 0.6425\n",
      "Epoch 326/500\n",
      " - 0s - loss: 0.0346 - accuracy: 0.8140 - val_loss: 0.0601 - val_accuracy: 0.6400\n",
      "Epoch 327/500\n",
      " - 0s - loss: 0.0350 - accuracy: 0.7990 - val_loss: 0.0601 - val_accuracy: 0.6400\n",
      "Epoch 328/500\n",
      " - 0s - loss: 0.0344 - accuracy: 0.8098 - val_loss: 0.0601 - val_accuracy: 0.6325\n",
      "Epoch 329/500\n",
      " - 0s - loss: 0.0348 - accuracy: 0.8107 - val_loss: 0.0599 - val_accuracy: 0.6375\n",
      "Epoch 330/500\n",
      " - 0s - loss: 0.0341 - accuracy: 0.8115 - val_loss: 0.0597 - val_accuracy: 0.6400\n",
      "Epoch 331/500\n",
      " - 0s - loss: 0.0348 - accuracy: 0.8123 - val_loss: 0.0597 - val_accuracy: 0.6400\n",
      "Epoch 332/500\n",
      " - 0s - loss: 0.0345 - accuracy: 0.8023 - val_loss: 0.0596 - val_accuracy: 0.6500\n",
      "Epoch 333/500\n",
      " - 0s - loss: 0.0344 - accuracy: 0.8082 - val_loss: 0.0598 - val_accuracy: 0.6450\n",
      "Epoch 334/500\n",
      " - 0s - loss: 0.0336 - accuracy: 0.8048 - val_loss: 0.0603 - val_accuracy: 0.6450\n",
      "Epoch 335/500\n",
      " - 0s - loss: 0.0341 - accuracy: 0.8115 - val_loss: 0.0606 - val_accuracy: 0.6425\n",
      "Epoch 336/500\n",
      " - 0s - loss: 0.0345 - accuracy: 0.8123 - val_loss: 0.0602 - val_accuracy: 0.6450\n",
      "Epoch 337/500\n",
      " - 0s - loss: 0.0335 - accuracy: 0.8148 - val_loss: 0.0601 - val_accuracy: 0.6450\n",
      "Epoch 338/500\n",
      " - 0s - loss: 0.0344 - accuracy: 0.8040 - val_loss: 0.0601 - val_accuracy: 0.6475\n",
      "Epoch 339/500\n",
      " - 0s - loss: 0.0340 - accuracy: 0.8040 - val_loss: 0.0599 - val_accuracy: 0.6475\n",
      "Epoch 340/500\n",
      " - 0s - loss: 0.0344 - accuracy: 0.8007 - val_loss: 0.0596 - val_accuracy: 0.6475\n",
      "Epoch 341/500\n",
      " - 0s - loss: 0.0348 - accuracy: 0.8015 - val_loss: 0.0593 - val_accuracy: 0.6550\n",
      "Epoch 342/500\n",
      " - 0s - loss: 0.0332 - accuracy: 0.8140 - val_loss: 0.0593 - val_accuracy: 0.6500\n",
      "Epoch 343/500\n",
      " - 0s - loss: 0.0337 - accuracy: 0.8032 - val_loss: 0.0595 - val_accuracy: 0.6575\n",
      "Epoch 344/500\n",
      " - 0s - loss: 0.0344 - accuracy: 0.8032 - val_loss: 0.0599 - val_accuracy: 0.6625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345/500\n",
      " - 0s - loss: 0.0329 - accuracy: 0.8257 - val_loss: 0.0600 - val_accuracy: 0.6525\n",
      "Epoch 346/500\n",
      " - 0s - loss: 0.0346 - accuracy: 0.8048 - val_loss: 0.0602 - val_accuracy: 0.6450\n",
      "Epoch 347/500\n",
      " - 0s - loss: 0.0340 - accuracy: 0.8098 - val_loss: 0.0601 - val_accuracy: 0.6425\n",
      "Epoch 348/500\n",
      " - 0s - loss: 0.0330 - accuracy: 0.8224 - val_loss: 0.0599 - val_accuracy: 0.6475\n",
      "Epoch 349/500\n",
      " - 0s - loss: 0.0341 - accuracy: 0.8107 - val_loss: 0.0600 - val_accuracy: 0.6475\n",
      "Epoch 350/500\n",
      " - 0s - loss: 0.0340 - accuracy: 0.8140 - val_loss: 0.0603 - val_accuracy: 0.6425\n",
      "Epoch 351/500\n",
      " - 0s - loss: 0.0334 - accuracy: 0.8190 - val_loss: 0.0602 - val_accuracy: 0.6475\n",
      "Epoch 352/500\n",
      " - 0s - loss: 0.0349 - accuracy: 0.8057 - val_loss: 0.0602 - val_accuracy: 0.6525\n",
      "Epoch 353/500\n",
      " - 0s - loss: 0.0326 - accuracy: 0.8207 - val_loss: 0.0604 - val_accuracy: 0.6600\n",
      "Epoch 354/500\n",
      " - 0s - loss: 0.0336 - accuracy: 0.8182 - val_loss: 0.0605 - val_accuracy: 0.6550\n",
      "Epoch 355/500\n",
      " - 0s - loss: 0.0343 - accuracy: 0.8107 - val_loss: 0.0606 - val_accuracy: 0.6550\n",
      "Epoch 356/500\n",
      " - 0s - loss: 0.0332 - accuracy: 0.8207 - val_loss: 0.0608 - val_accuracy: 0.6425\n",
      "Epoch 357/500\n",
      " - 0s - loss: 0.0325 - accuracy: 0.8249 - val_loss: 0.0609 - val_accuracy: 0.6375\n",
      "Epoch 358/500\n",
      " - 0s - loss: 0.0335 - accuracy: 0.8190 - val_loss: 0.0607 - val_accuracy: 0.6450\n",
      "Epoch 359/500\n",
      " - 0s - loss: 0.0330 - accuracy: 0.8140 - val_loss: 0.0608 - val_accuracy: 0.6400\n",
      "Epoch 360/500\n",
      " - 0s - loss: 0.0334 - accuracy: 0.8132 - val_loss: 0.0602 - val_accuracy: 0.6500\n",
      "Epoch 361/500\n",
      " - 0s - loss: 0.0346 - accuracy: 0.8048 - val_loss: 0.0601 - val_accuracy: 0.6550\n",
      "Epoch 362/500\n",
      " - 0s - loss: 0.0341 - accuracy: 0.8090 - val_loss: 0.0604 - val_accuracy: 0.6475\n",
      "Epoch 363/500\n",
      " - 0s - loss: 0.0325 - accuracy: 0.8224 - val_loss: 0.0606 - val_accuracy: 0.6525\n",
      "Epoch 364/500\n",
      " - 0s - loss: 0.0339 - accuracy: 0.8123 - val_loss: 0.0603 - val_accuracy: 0.6475\n",
      "Epoch 365/500\n",
      " - 0s - loss: 0.0334 - accuracy: 0.8224 - val_loss: 0.0600 - val_accuracy: 0.6450\n",
      "Epoch 366/500\n",
      " - 0s - loss: 0.0336 - accuracy: 0.8073 - val_loss: 0.0598 - val_accuracy: 0.6450\n",
      "Epoch 367/500\n",
      " - 0s - loss: 0.0332 - accuracy: 0.8132 - val_loss: 0.0598 - val_accuracy: 0.6475\n",
      "Epoch 368/500\n",
      " - 0s - loss: 0.0330 - accuracy: 0.8274 - val_loss: 0.0601 - val_accuracy: 0.6425\n",
      "Epoch 369/500\n",
      " - 0s - loss: 0.0326 - accuracy: 0.8332 - val_loss: 0.0604 - val_accuracy: 0.6475\n",
      "Epoch 370/500\n",
      " - 0s - loss: 0.0335 - accuracy: 0.8132 - val_loss: 0.0603 - val_accuracy: 0.6450\n",
      "Epoch 371/500\n",
      " - 0s - loss: 0.0322 - accuracy: 0.8265 - val_loss: 0.0604 - val_accuracy: 0.6425\n",
      "Epoch 372/500\n",
      " - 0s - loss: 0.0321 - accuracy: 0.8232 - val_loss: 0.0604 - val_accuracy: 0.6525\n",
      "Epoch 373/500\n",
      " - 0s - loss: 0.0328 - accuracy: 0.8190 - val_loss: 0.0606 - val_accuracy: 0.6500\n",
      "Epoch 374/500\n",
      " - 0s - loss: 0.0334 - accuracy: 0.8148 - val_loss: 0.0604 - val_accuracy: 0.6525\n",
      "Epoch 375/500\n",
      " - 0s - loss: 0.0327 - accuracy: 0.8224 - val_loss: 0.0605 - val_accuracy: 0.6475\n",
      "Epoch 376/500\n",
      " - 0s - loss: 0.0328 - accuracy: 0.8190 - val_loss: 0.0606 - val_accuracy: 0.6525\n",
      "Epoch 377/500\n",
      " - 0s - loss: 0.0324 - accuracy: 0.8299 - val_loss: 0.0607 - val_accuracy: 0.6525\n",
      "Epoch 378/500\n",
      " - 0s - loss: 0.0326 - accuracy: 0.8215 - val_loss: 0.0605 - val_accuracy: 0.6600\n",
      "Epoch 379/500\n",
      " - 0s - loss: 0.0320 - accuracy: 0.8198 - val_loss: 0.0602 - val_accuracy: 0.6500\n",
      "Epoch 380/500\n",
      " - 0s - loss: 0.0324 - accuracy: 0.8165 - val_loss: 0.0603 - val_accuracy: 0.6425\n",
      "Epoch 381/500\n",
      " - 0s - loss: 0.0320 - accuracy: 0.8232 - val_loss: 0.0602 - val_accuracy: 0.6425\n",
      "Epoch 382/500\n",
      " - 0s - loss: 0.0323 - accuracy: 0.8240 - val_loss: 0.0604 - val_accuracy: 0.6475\n",
      "Epoch 383/500\n",
      " - 0s - loss: 0.0326 - accuracy: 0.8207 - val_loss: 0.0609 - val_accuracy: 0.6475\n",
      "Epoch 384/500\n",
      " - 0s - loss: 0.0320 - accuracy: 0.8240 - val_loss: 0.0608 - val_accuracy: 0.6500\n",
      "Epoch 385/500\n",
      " - 0s - loss: 0.0328 - accuracy: 0.8249 - val_loss: 0.0610 - val_accuracy: 0.6500\n",
      "Epoch 386/500\n",
      " - 0s - loss: 0.0323 - accuracy: 0.8232 - val_loss: 0.0608 - val_accuracy: 0.6525\n",
      "Epoch 387/500\n",
      " - 0s - loss: 0.0323 - accuracy: 0.8265 - val_loss: 0.0604 - val_accuracy: 0.6400\n",
      "Epoch 388/500\n",
      " - 0s - loss: 0.0325 - accuracy: 0.8123 - val_loss: 0.0604 - val_accuracy: 0.6400\n",
      "Epoch 389/500\n",
      " - 0s - loss: 0.0329 - accuracy: 0.8215 - val_loss: 0.0606 - val_accuracy: 0.6325\n",
      "Epoch 390/500\n",
      " - 0s - loss: 0.0329 - accuracy: 0.8232 - val_loss: 0.0605 - val_accuracy: 0.6325\n",
      "Epoch 391/500\n",
      " - 0s - loss: 0.0322 - accuracy: 0.8107 - val_loss: 0.0608 - val_accuracy: 0.6450\n",
      "Epoch 392/500\n",
      " - 0s - loss: 0.0326 - accuracy: 0.8123 - val_loss: 0.0609 - val_accuracy: 0.6400\n",
      "Epoch 393/500\n",
      " - 0s - loss: 0.0319 - accuracy: 0.8249 - val_loss: 0.0611 - val_accuracy: 0.6525\n",
      "Epoch 394/500\n",
      " - 0s - loss: 0.0330 - accuracy: 0.8165 - val_loss: 0.0609 - val_accuracy: 0.6375\n",
      "Epoch 395/500\n",
      " - 0s - loss: 0.0320 - accuracy: 0.8332 - val_loss: 0.0611 - val_accuracy: 0.6475\n",
      "Epoch 396/500\n",
      " - 0s - loss: 0.0326 - accuracy: 0.8224 - val_loss: 0.0612 - val_accuracy: 0.6600\n",
      "Epoch 397/500\n",
      " - 0s - loss: 0.0313 - accuracy: 0.8265 - val_loss: 0.0612 - val_accuracy: 0.6600\n",
      "Epoch 398/500\n",
      " - 0s - loss: 0.0333 - accuracy: 0.8048 - val_loss: 0.0612 - val_accuracy: 0.6450\n",
      "Epoch 399/500\n",
      " - 0s - loss: 0.0324 - accuracy: 0.8299 - val_loss: 0.0609 - val_accuracy: 0.6425\n",
      "Epoch 400/500\n",
      " - 0s - loss: 0.0328 - accuracy: 0.8198 - val_loss: 0.0606 - val_accuracy: 0.6475\n",
      "Epoch 401/500\n",
      " - 0s - loss: 0.0325 - accuracy: 0.8073 - val_loss: 0.0602 - val_accuracy: 0.6500\n",
      "Epoch 402/500\n",
      " - 0s - loss: 0.0325 - accuracy: 0.8140 - val_loss: 0.0604 - val_accuracy: 0.6475\n",
      "Epoch 403/500\n",
      " - 0s - loss: 0.0322 - accuracy: 0.8249 - val_loss: 0.0606 - val_accuracy: 0.6475\n",
      "Epoch 404/500\n",
      " - 0s - loss: 0.0317 - accuracy: 0.8315 - val_loss: 0.0607 - val_accuracy: 0.6475\n",
      "Epoch 405/500\n",
      " - 0s - loss: 0.0327 - accuracy: 0.8173 - val_loss: 0.0608 - val_accuracy: 0.6525\n",
      "Epoch 406/500\n",
      " - 0s - loss: 0.0324 - accuracy: 0.8232 - val_loss: 0.0606 - val_accuracy: 0.6550\n",
      "Epoch 407/500\n",
      " - 0s - loss: 0.0324 - accuracy: 0.8232 - val_loss: 0.0606 - val_accuracy: 0.6550\n",
      "Epoch 408/500\n",
      " - 0s - loss: 0.0327 - accuracy: 0.8249 - val_loss: 0.0602 - val_accuracy: 0.6500\n",
      "Epoch 409/500\n",
      " - 0s - loss: 0.0310 - accuracy: 0.8390 - val_loss: 0.0598 - val_accuracy: 0.6650\n",
      "Epoch 410/500\n",
      " - 0s - loss: 0.0305 - accuracy: 0.8432 - val_loss: 0.0599 - val_accuracy: 0.6575\n",
      "Epoch 411/500\n",
      " - 0s - loss: 0.0312 - accuracy: 0.8332 - val_loss: 0.0599 - val_accuracy: 0.6550\n",
      "Epoch 412/500\n",
      " - 0s - loss: 0.0311 - accuracy: 0.8390 - val_loss: 0.0603 - val_accuracy: 0.6600\n",
      "Epoch 413/500\n",
      " - 0s - loss: 0.0315 - accuracy: 0.8240 - val_loss: 0.0605 - val_accuracy: 0.6625\n",
      "Epoch 414/500\n",
      " - 0s - loss: 0.0300 - accuracy: 0.8357 - val_loss: 0.0608 - val_accuracy: 0.6525\n",
      "Epoch 415/500\n",
      " - 0s - loss: 0.0322 - accuracy: 0.8215 - val_loss: 0.0608 - val_accuracy: 0.6500\n",
      "Epoch 416/500\n",
      " - 0s - loss: 0.0321 - accuracy: 0.8282 - val_loss: 0.0602 - val_accuracy: 0.6525\n",
      "Epoch 417/500\n",
      " - 0s - loss: 0.0305 - accuracy: 0.8390 - val_loss: 0.0599 - val_accuracy: 0.6550\n",
      "Epoch 418/500\n",
      " - 0s - loss: 0.0307 - accuracy: 0.8357 - val_loss: 0.0600 - val_accuracy: 0.6500\n",
      "Epoch 419/500\n",
      " - 0s - loss: 0.0313 - accuracy: 0.8307 - val_loss: 0.0599 - val_accuracy: 0.6500\n",
      "Epoch 420/500\n",
      " - 0s - loss: 0.0305 - accuracy: 0.8424 - val_loss: 0.0600 - val_accuracy: 0.6475\n",
      "Epoch 421/500\n",
      " - 0s - loss: 0.0310 - accuracy: 0.8382 - val_loss: 0.0603 - val_accuracy: 0.6450\n",
      "Epoch 422/500\n",
      " - 0s - loss: 0.0313 - accuracy: 0.8349 - val_loss: 0.0606 - val_accuracy: 0.6525\n",
      "Epoch 423/500\n",
      " - 0s - loss: 0.0324 - accuracy: 0.8182 - val_loss: 0.0605 - val_accuracy: 0.6500\n",
      "Epoch 424/500\n",
      " - 0s - loss: 0.0308 - accuracy: 0.8315 - val_loss: 0.0604 - val_accuracy: 0.6525\n",
      "Epoch 425/500\n",
      " - 0s - loss: 0.0301 - accuracy: 0.8474 - val_loss: 0.0604 - val_accuracy: 0.6525\n",
      "Epoch 426/500\n",
      " - 0s - loss: 0.0310 - accuracy: 0.8390 - val_loss: 0.0603 - val_accuracy: 0.6525\n",
      "Epoch 427/500\n",
      " - 0s - loss: 0.0307 - accuracy: 0.8374 - val_loss: 0.0603 - val_accuracy: 0.6450\n",
      "Epoch 428/500\n",
      " - 0s - loss: 0.0303 - accuracy: 0.8399 - val_loss: 0.0606 - val_accuracy: 0.6475\n",
      "Epoch 429/500\n",
      " - 0s - loss: 0.0309 - accuracy: 0.8307 - val_loss: 0.0609 - val_accuracy: 0.6450\n",
      "Epoch 430/500\n",
      " - 0s - loss: 0.0301 - accuracy: 0.8457 - val_loss: 0.0609 - val_accuracy: 0.6550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 431/500\n",
      " - 0s - loss: 0.0316 - accuracy: 0.8299 - val_loss: 0.0610 - val_accuracy: 0.6525\n",
      "Epoch 432/500\n",
      " - 0s - loss: 0.0307 - accuracy: 0.8382 - val_loss: 0.0609 - val_accuracy: 0.6575\n",
      "Epoch 433/500\n",
      " - 0s - loss: 0.0316 - accuracy: 0.8207 - val_loss: 0.0609 - val_accuracy: 0.6575\n",
      "Epoch 434/500\n",
      " - 0s - loss: 0.0314 - accuracy: 0.8324 - val_loss: 0.0606 - val_accuracy: 0.6500\n",
      "Epoch 435/500\n",
      " - 0s - loss: 0.0313 - accuracy: 0.8374 - val_loss: 0.0608 - val_accuracy: 0.6500\n",
      "Epoch 436/500\n",
      " - 0s - loss: 0.0320 - accuracy: 0.8349 - val_loss: 0.0613 - val_accuracy: 0.6400\n",
      "Epoch 437/500\n",
      " - 0s - loss: 0.0316 - accuracy: 0.8299 - val_loss: 0.0613 - val_accuracy: 0.6475\n",
      "Epoch 438/500\n",
      " - 0s - loss: 0.0305 - accuracy: 0.8374 - val_loss: 0.0609 - val_accuracy: 0.6525\n",
      "Epoch 439/500\n",
      " - 0s - loss: 0.0303 - accuracy: 0.8324 - val_loss: 0.0607 - val_accuracy: 0.6525\n",
      "Epoch 440/500\n",
      " - 0s - loss: 0.0301 - accuracy: 0.8332 - val_loss: 0.0609 - val_accuracy: 0.6450\n",
      "Epoch 441/500\n",
      " - 0s - loss: 0.0303 - accuracy: 0.8407 - val_loss: 0.0611 - val_accuracy: 0.6450\n",
      "Epoch 442/500\n",
      " - 0s - loss: 0.0304 - accuracy: 0.8365 - val_loss: 0.0611 - val_accuracy: 0.6300\n",
      "Epoch 443/500\n",
      " - 0s - loss: 0.0309 - accuracy: 0.8357 - val_loss: 0.0612 - val_accuracy: 0.6475\n",
      "Epoch 444/500\n",
      " - 0s - loss: 0.0309 - accuracy: 0.8240 - val_loss: 0.0614 - val_accuracy: 0.6450\n",
      "Epoch 445/500\n",
      " - 0s - loss: 0.0309 - accuracy: 0.8307 - val_loss: 0.0612 - val_accuracy: 0.6550\n",
      "Epoch 446/500\n",
      " - 0s - loss: 0.0311 - accuracy: 0.8265 - val_loss: 0.0609 - val_accuracy: 0.6475\n",
      "Epoch 447/500\n",
      " - 0s - loss: 0.0311 - accuracy: 0.8332 - val_loss: 0.0608 - val_accuracy: 0.6450\n",
      "Epoch 448/500\n",
      " - 0s - loss: 0.0301 - accuracy: 0.8324 - val_loss: 0.0610 - val_accuracy: 0.6425\n",
      "Epoch 449/500\n",
      " - 0s - loss: 0.0300 - accuracy: 0.8432 - val_loss: 0.0610 - val_accuracy: 0.6425\n",
      "Epoch 450/500\n",
      " - 0s - loss: 0.0308 - accuracy: 0.8357 - val_loss: 0.0608 - val_accuracy: 0.6450\n",
      "Epoch 451/500\n",
      " - 0s - loss: 0.0303 - accuracy: 0.8374 - val_loss: 0.0609 - val_accuracy: 0.6475\n",
      "Epoch 452/500\n",
      " - 0s - loss: 0.0299 - accuracy: 0.8424 - val_loss: 0.0609 - val_accuracy: 0.6475\n",
      "Epoch 453/500\n",
      " - 0s - loss: 0.0301 - accuracy: 0.8407 - val_loss: 0.0609 - val_accuracy: 0.6425\n",
      "Epoch 454/500\n",
      " - 0s - loss: 0.0297 - accuracy: 0.8432 - val_loss: 0.0614 - val_accuracy: 0.6450\n",
      "Epoch 455/500\n",
      " - 0s - loss: 0.0309 - accuracy: 0.8357 - val_loss: 0.0616 - val_accuracy: 0.6425\n",
      "Epoch 456/500\n",
      " - 0s - loss: 0.0301 - accuracy: 0.8399 - val_loss: 0.0616 - val_accuracy: 0.6450\n",
      "Epoch 457/500\n",
      " - 0s - loss: 0.0303 - accuracy: 0.8307 - val_loss: 0.0614 - val_accuracy: 0.6450\n",
      "Epoch 458/500\n",
      " - 0s - loss: 0.0296 - accuracy: 0.8357 - val_loss: 0.0613 - val_accuracy: 0.6400\n",
      "Epoch 459/500\n",
      " - 0s - loss: 0.0302 - accuracy: 0.8415 - val_loss: 0.0615 - val_accuracy: 0.6375\n",
      "Epoch 460/500\n",
      " - 0s - loss: 0.0299 - accuracy: 0.8365 - val_loss: 0.0615 - val_accuracy: 0.6475\n",
      "Epoch 461/500\n",
      " - 0s - loss: 0.0303 - accuracy: 0.8315 - val_loss: 0.0610 - val_accuracy: 0.6500\n",
      "Epoch 462/500\n",
      " - 0s - loss: 0.0305 - accuracy: 0.8340 - val_loss: 0.0607 - val_accuracy: 0.6500\n",
      "Epoch 463/500\n",
      " - 0s - loss: 0.0301 - accuracy: 0.8357 - val_loss: 0.0607 - val_accuracy: 0.6575\n",
      "Epoch 464/500\n",
      " - 0s - loss: 0.0301 - accuracy: 0.8415 - val_loss: 0.0608 - val_accuracy: 0.6400\n",
      "Epoch 465/500\n",
      " - 0s - loss: 0.0295 - accuracy: 0.8432 - val_loss: 0.0611 - val_accuracy: 0.6425\n",
      "Epoch 466/500\n",
      " - 0s - loss: 0.0298 - accuracy: 0.8432 - val_loss: 0.0612 - val_accuracy: 0.6375\n",
      "Epoch 467/500\n",
      " - 0s - loss: 0.0300 - accuracy: 0.8390 - val_loss: 0.0613 - val_accuracy: 0.6400\n",
      "Epoch 468/500\n",
      " - 0s - loss: 0.0293 - accuracy: 0.8324 - val_loss: 0.0616 - val_accuracy: 0.6475\n",
      "Epoch 469/500\n",
      " - 0s - loss: 0.0302 - accuracy: 0.8432 - val_loss: 0.0618 - val_accuracy: 0.6525\n",
      "Epoch 470/500\n",
      " - 0s - loss: 0.0313 - accuracy: 0.8224 - val_loss: 0.0614 - val_accuracy: 0.6550\n",
      "Epoch 471/500\n",
      " - 0s - loss: 0.0305 - accuracy: 0.8265 - val_loss: 0.0614 - val_accuracy: 0.6400\n",
      "Epoch 472/500\n",
      " - 0s - loss: 0.0292 - accuracy: 0.8415 - val_loss: 0.0614 - val_accuracy: 0.6425\n",
      "Epoch 473/500\n",
      " - 0s - loss: 0.0303 - accuracy: 0.8324 - val_loss: 0.0612 - val_accuracy: 0.6425\n",
      "Epoch 474/500\n",
      " - 0s - loss: 0.0293 - accuracy: 0.8482 - val_loss: 0.0610 - val_accuracy: 0.6525\n",
      "Epoch 475/500\n",
      " - 0s - loss: 0.0298 - accuracy: 0.8432 - val_loss: 0.0608 - val_accuracy: 0.6475\n",
      "Epoch 476/500\n",
      " - 0s - loss: 0.0301 - accuracy: 0.8399 - val_loss: 0.0609 - val_accuracy: 0.6500\n",
      "Epoch 477/500\n",
      " - 0s - loss: 0.0299 - accuracy: 0.8349 - val_loss: 0.0610 - val_accuracy: 0.6400\n",
      "Epoch 478/500\n",
      " - 0s - loss: 0.0300 - accuracy: 0.8290 - val_loss: 0.0609 - val_accuracy: 0.6425\n",
      "Epoch 479/500\n",
      " - 0s - loss: 0.0292 - accuracy: 0.8490 - val_loss: 0.0609 - val_accuracy: 0.6400\n",
      "Epoch 480/500\n",
      " - 0s - loss: 0.0297 - accuracy: 0.8315 - val_loss: 0.0613 - val_accuracy: 0.6400\n",
      "Epoch 481/500\n",
      " - 0s - loss: 0.0294 - accuracy: 0.8449 - val_loss: 0.0613 - val_accuracy: 0.6425\n",
      "Epoch 482/500\n",
      " - 0s - loss: 0.0292 - accuracy: 0.8424 - val_loss: 0.0615 - val_accuracy: 0.6400\n",
      "Epoch 483/500\n",
      " - 0s - loss: 0.0302 - accuracy: 0.8374 - val_loss: 0.0613 - val_accuracy: 0.6500\n",
      "Epoch 484/500\n",
      " - 0s - loss: 0.0296 - accuracy: 0.8390 - val_loss: 0.0612 - val_accuracy: 0.6450\n",
      "Epoch 485/500\n",
      " - 0s - loss: 0.0300 - accuracy: 0.8415 - val_loss: 0.0611 - val_accuracy: 0.6425\n",
      "Epoch 486/500\n",
      " - 0s - loss: 0.0290 - accuracy: 0.8457 - val_loss: 0.0612 - val_accuracy: 0.6475\n",
      "Epoch 487/500\n",
      " - 0s - loss: 0.0287 - accuracy: 0.8524 - val_loss: 0.0611 - val_accuracy: 0.6475\n",
      "Epoch 488/500\n",
      " - 0s - loss: 0.0292 - accuracy: 0.8449 - val_loss: 0.0612 - val_accuracy: 0.6325\n",
      "Epoch 489/500\n",
      " - 0s - loss: 0.0293 - accuracy: 0.8449 - val_loss: 0.0613 - val_accuracy: 0.6400\n",
      "Epoch 490/500\n",
      " - 0s - loss: 0.0283 - accuracy: 0.8474 - val_loss: 0.0612 - val_accuracy: 0.6425\n",
      "Epoch 491/500\n",
      " - 0s - loss: 0.0289 - accuracy: 0.8532 - val_loss: 0.0612 - val_accuracy: 0.6425\n",
      "Epoch 492/500\n",
      " - 0s - loss: 0.0282 - accuracy: 0.8582 - val_loss: 0.0610 - val_accuracy: 0.6500\n",
      "Epoch 493/500\n",
      " - 0s - loss: 0.0307 - accuracy: 0.8332 - val_loss: 0.0609 - val_accuracy: 0.6425\n",
      "Epoch 494/500\n",
      " - 0s - loss: 0.0299 - accuracy: 0.8390 - val_loss: 0.0608 - val_accuracy: 0.6525\n",
      "Epoch 495/500\n",
      " - 0s - loss: 0.0296 - accuracy: 0.8424 - val_loss: 0.0607 - val_accuracy: 0.6425\n",
      "Epoch 496/500\n",
      " - 0s - loss: 0.0292 - accuracy: 0.8415 - val_loss: 0.0607 - val_accuracy: 0.6550\n",
      "Epoch 497/500\n",
      " - 0s - loss: 0.0296 - accuracy: 0.8357 - val_loss: 0.0611 - val_accuracy: 0.6550\n",
      "Epoch 498/500\n",
      " - 0s - loss: 0.0288 - accuracy: 0.8482 - val_loss: 0.0611 - val_accuracy: 0.6575\n",
      "Epoch 499/500\n",
      " - 0s - loss: 0.0290 - accuracy: 0.8374 - val_loss: 0.0611 - val_accuracy: 0.6575\n",
      "Epoch 500/500\n",
      " - 0s - loss: 0.0299 - accuracy: 0.8374 - val_loss: 0.0616 - val_accuracy: 0.6525\n"
     ]
    }
   ],
   "source": [
    "model_history = best_NN_model.fit(\n",
    "    X_train_scaled, y_train_categorical,\n",
    "    epochs=epochs, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    validation_data=(X_test_scaled, y_test_categorical)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.68      0.78      0.73       169\n",
      "           6       0.61      0.63      0.62       149\n",
      "           7       0.66      0.58      0.62        60\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.65       400\n",
      "   macro avg       0.33      0.33      0.33       400\n",
      "weighted avg       0.62      0.65      0.63       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_predicts = best_NN_model.predict_classes(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_test, best_predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.061596411466598514, Accuracy: 0.6524999737739563\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the testing data\n",
    "model_loss, model_accuracy = best_NN_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ebb5ba4eb8>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss function\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(model_history.history['loss']), 'r', label='train')\n",
    "ax.plot(np.sqrt(model_history.history['val_loss']), 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "# Plot the accuracy\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(model_history.history['accuracy']), 'r', label='train')\n",
    "ax.plot(np.sqrt(model_history.history['val_accuracy']), 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Accuracy', fontsize=20)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Save and Load the Trained Models\n",
    "We can save our trained models using the HDF5 binary format with the extension `.h5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### save the model with model.sav & joblib.dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "def save_NN_model(model_rootfile, model, xscaler, yscaler) :\n",
    "    model_filename = model_rootfile + '.h5'\n",
    "    model_filepath = os.path.join(\".\", \"saved_models\", model_filename )\n",
    "\n",
    "    print('Model Save File: ', model_filepath)\n",
    "    model.save(model_filepath)\n",
    "    \n",
    "    #save the y_scaler also to invert the predictions\n",
    "    model_yscaler_filename = model_rootfile + \"_yscaler.sav\"\n",
    "    model_yscaler_filepath = os.path.join(\".\", \"saved_models\", model_yscaler_filename)\n",
    "\n",
    "    print('y_scaler Save File: ', model_yscaler_filepath)\n",
    "    joblib.dump(y_scaler, model_yscaler_filepath)\n",
    "\n",
    "    model_xscaler_filename = model_rootfile + \"_xscaler.sav\"\n",
    "    model_xscaler_filepath = os.path.join(\".\", \"saved_models\", model_xscaler_filename)\n",
    "\n",
    "    print('x_scaler Save File: ', model_xscaler_filepath)\n",
    "    joblib.dump(X_scaler, model_xscaler_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Save File:  .\\saved_models\\jc_redwine_first_NN.h5\n",
      "y_scaler Save File:  .\\saved_models\\jc_redwine_first_NN_yscaler.sav\n",
      "x_scaler Save File:  .\\saved_models\\jc_redwine_first_NN_xscaler.sav\n"
     ]
    }
   ],
   "source": [
    "save_NN_model(\"jc_redwine_first_NN\", model, X_scaler, y_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Save File:  .\\saved_models\\jc_redwine_grid_NN.h5\n",
      "y_scaler Save File:  .\\saved_models\\jc_redwine_grid_NN_yscaler.sav\n",
      "x_scaler Save File:  .\\saved_models\\jc_redwine_grid_NN_xscaler.sav\n"
     ]
    }
   ],
   "source": [
    "save_NN_model(\"jc_redwine_grid_NN\", best_NN_model, X_scaler, y_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### load the saved models to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model \n",
    "load_first_trained = load_model(\".\\saved_models\\jc_redwine_grid_NN.h5\")\n",
    "load_best_grid = load_model(\".\\saved_models\\jc_redwine_grid_NN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with both models\n",
    "first_predicts = load_first_trained.predict_classes(X_test_scaled)\n",
    "grid_predicts = load_best_grid.predict_classes(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My Original Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.68      0.78      0.73       169\n",
      "           6       0.61      0.63      0.62       149\n",
      "           7       0.66      0.58      0.62        60\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.65       400\n",
      "   macro avg       0.33      0.33      0.33       400\n",
      "weighted avg       0.62      0.65      0.63       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimco\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# score the models\n",
    "print(classification_report(y_test, first_predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Grid Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.68      0.78      0.73       169\n",
      "           6       0.61      0.63      0.62       149\n",
      "           7       0.66      0.58      0.62        60\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.65       400\n",
      "   macro avg       0.33      0.33      0.33       400\n",
      "weighted avg       0.62      0.65      0.63       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, grid_predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMMENTARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My GridSerach did not do a great job of refining parameters for my Neural Net model.  Need to tune other parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would go with my orginal first trained NN."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
